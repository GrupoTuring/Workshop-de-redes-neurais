{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5cd74ba85a3b6a037c59ac3f3634fcdd9437555c9fe253dd51f04000fcd493e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Workshop Redes Neurais\n",
    "## Grupo Turing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Proposta de roteiro para o nb (deletar depois)\n",
    "\n",
    "#### O que deve ser falado antes do nb?\n",
    "- Introdução à redes neurais\n",
    "- estrutura geral de uma rede neural (talvez falar que é parecido com uma regressão logística?)\n",
    "- computation graph (talvez?)\n",
    "- forward propagation\n",
    "- back propagation (se falar de fp acho que é a sequência lógica)\n",
    "- optimizaçaõ e gradient descent\n",
    "\n",
    "#### Conteúdos do nb\n",
    "- Básico de Pytorch\n",
    "  - comparação com np\n",
    "  - operações básicas\n",
    "  - Variables (falar de back propagation?)\n",
    "- Implementando uma NN\n",
    "  - Implementar uma regressão logística (?)\n",
    "  - Implementar NN\n",
    "  - Falar sobre CNN e LSTM (?)\n",
    "  \n",
    "**Obs: ** Ainda é preciso deixar o NB mais bonito, mais imagens e talvez melhorar a estrura dos exemplos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Básicos de Pytorch\n",
    "\n",
    "Primeiro vamos ver alguns análogos entre **numpy** e **Pytorch**\n",
    "\n",
    "### Matrizes\n",
    " - Em Pytorch, matrizes (*arrays*) são chamados de tensores.\n",
    " - Uma matriz $3\\times3$, por exemplo é um tensor $3\\times3$\n",
    " - Podemos criar um array numpy com o método `np.numpy()`\n",
    " - Podemos pegar o tipo do array com `type()`\n",
    " - Podemos pegar o formato do *array* com `np.shape()`. Linha $\\times$ Coluna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array do tipo: <class 'numpy.ndarray'>\nArray de formato: (2, 3)\n[[1 2 3]\n [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "array = [[1,2,3],[4,5,6]]\n",
    "primeiro_array = np.array(array) # array 2x3\n",
    "print(f\"Array do tipo: {type(primeiro_array)}\")\n",
    "print(f\"Array de formato: {np.shape(primeiro_array)}\")\n",
    "print(primeiro_array)"
   ]
  },
  {
   "source": [
    "- Criamos um tensor com o método `torch.Tensor()`\n",
    "- `tensor.type`: tipo do *array*, nesse caso um tensor\n",
    "- `tensor.shape`: formato do *array*. Linha $\\times$ Coluna "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array do tipo: <built-in method type of Tensor object at 0x7f6d80035340>\nArray de formato: torch.Size([2, 3])\ntensor([[1., 2., 3.],\n        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.Tensor(array)\n",
    "print(f\"Array do tipo: {tensor.type}\")\n",
    "print(f\"Array de formato: {tensor.shape}\")\n",
    "print(tensor)"
   ]
  },
  {
   "source": [
    "Podemos fazer a alocação de *arrays* de maneira análoga nas duas linguagens:\n",
    " - `np.ones()` = `torch.ones()`\n",
    " - `np.random.rand()` = `torch.rand()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy:\n [[1. 1. 1.]\n [1. 1. 1.]]\n\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numpy:\\n {np.ones((2,3))}\\n\")\n",
    "\n",
    "print(torch.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy:\n [[0.02922832 0.22597871 0.46795265]\n [0.08224265 0.26849427 0.39498793]]\n\ntensor([[0.2948, 0.8579, 0.9159],\n        [0.3602, 0.7019, 0.9748]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numpy:\\n {np.random.rand(2,3)}\\n\")\n",
    "\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "source": [
    "Em muitos pontos **numpy** e **pytorch** são bem parecidos em suas estruturas, e muitas das vezes podemos utilizar os dois em conjunto. Assim normalmente convertemos resultados de redes neurais - que são tensores - para **arrays** de **numpy**.\n",
    "\n",
    "Os métodos para fazer a conversão entre tensores e arrays numpy:\n",
    " - `torch.from_numpy()`: de um array numpy para um tensore\n",
    " - `numpy()`: de um tensor para um array numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'> \n [[0.31502705 0.53426584]\n [0.87299971 0.32804781]] \n\ntensor([[0.3150, 0.5343],\n        [0.8730, 0.3280]], dtype=torch.float64) \n\n<class 'numpy.ndarray'> \n [[0.31502705 0.53426584]\n [0.87299971 0.32804781]]\n"
     ]
    }
   ],
   "source": [
    "array = np.random.rand(2,2)\n",
    "print(f\"{type(array)} \\n {array} \\n\")\n",
    "\n",
    "de_numpy_para_tensor = torch.from_numpy(array)\n",
    "print(f\"{de_numpy_para_tensor} \\n\")\n",
    "\n",
    "tensor = de_numpy_para_tensor\n",
    "de_tensor_para_numpy = tensor.numpy()\n",
    "print(f\"{type(de_tensor_para_numpy)} \\n {de_tensor_para_numpy}\")"
   ]
  },
  {
   "source": [
    "### Matemática básica com Pytorch\n",
    "*considere a e b dois tensores*\n",
    "\n",
    "- Redefinir o tamanho: `view()`\n",
    "- Adição: `torch.add(a,b)` = a + b\n",
    "- Subtração: `a.sub(b)` = a - b\n",
    "- Multiplicação elemento-a-elemento = `torch.mul(a,b)` = a * b\n",
    "- Divisão elemento-a-elemento = torch.div(a,b) = a / b\n",
    "- Média: a.mean()\n",
    "- Desvio Padrão (Standart Deviantion - std): a.std()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\ntorch.Size([9]): tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]) \n\nAdição: \ntensor([[2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.]]) \n\nSubtração: \ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]]) \n\nMultiplicação elemento-a-elemento: \ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\nDivisão elemento-a-elemento: \ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\nMédia: 3.0 \n\nDesvio padrão: 1.5811388492584229 \n\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(3,3)\n",
    "print(\"\\n\", tensor, \"\\n\")\n",
    "\n",
    "print(f\"{tensor.view(9).shape}: {tensor.view(9)} \\n\")\n",
    "\n",
    "print(f\"Adição: \\n{torch.add(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Subtração: \\n{torch.sub(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Multiplicação elemento-a-elemento: \\n{torch.mul(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Divisão elemento-a-elemento: \\n{torch.div(tensor, tensor)} \\n\")\n",
    "\n",
    "tensor = torch.Tensor([1,2,3,4,5])\n",
    "print(f\"Média: {tensor.mean()} \\n\")\n",
    "\n",
    "print(f\"Desvio padrão: {tensor.std()} \\n\")"
   ]
  },
  {
   "source": [
    "### Variáveis\n",
    "\n",
    "- Acumulam os gradientes\n",
    "- Na rede neural utilizaremos pytorch. Como explicamos anteriormente nas, redes neurais os gradientes são calculados na *backpropagation*.\n",
    "- A diferença entre variáveis e tensores é a de que variáveis acumulam os gradientes\n",
    "- Também podemos fazer operações matemáticas com variáveis\n",
    "- Dessa maneira, se queremos fazer a *backpropagation* precisamos de variáveis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "var = Variable(torch.ones(3), requires_grad = True)\n",
    "var"
   ]
  },
  {
   "source": [
    "Vamos ver um exemplo de como as Variávies são utilizadas em uma *backpropagation*, com duas função $f(y) = \\sum y$, $y(x) = x^2$ e $x = (3,5)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " x = tensor([3., 5.], requires_grad=True)\n f =  34.0\nGradientes: tensor([ 6., 10.])\n"
     ]
    }
   ],
   "source": [
    "array = [3,5]\n",
    "tensor = torch.Tensor(array)\n",
    "x = Variable(tensor, requires_grad = True)\n",
    "y = x**2\n",
    "print(f\" x = {x}\")\n",
    "\n",
    "f = sum(y)\n",
    "print(f\" f =  {f}\")\n",
    "\n",
    "f.backward() # Realiza as derivadas parciais\n",
    "\n",
    "print(f\"Gradientes: {x.grad}\")"
   ]
  },
  {
   "source": [
    "Vamos explicar passo a passo quais foram as operações feitas pelo Pytorch:\n",
    "- Primeiro ele recebe os elementos do tensor e faz a primeira operação com eles $y_1 = 3^2 = 9$ e $y_2 = 5^2 = 25$\n",
    "- Agora ele soma o tensor, retornando assim um único valor escalar: $\\sum_i y_i = y_1 + y_2 = 9 + 25 = 34$\n",
    "- O gradiente é a derivada parcial de cada elemento, ou seja o gradiente \"1\" é a derivada relativa à $y_1$ e o gradiente \"2\" é relativo à $y_2$ \n",
    "- derivada relativa à $y_1$ é $\\frac{\\partial}{\\partial y_1}(3^2) = 2*3 = 6$\n",
    "- derivada relativa à $y_2$ é $\\frac{\\partial}{\\partial y_2}(5^2) = 2*5 = 10$\n",
    "- Assim ficamos com os gradientes $(6, 10)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercícios\n",
    "\n",
    "Coplete às células de código abaixo no campo indicado por \"...\":"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Crie um tensor com base no *array* dado:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'...'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "array = [[10,100,1000], [20,200,2000]]\n",
    "tensor = \"...\"\n",
    "tensor"
   ]
  },
  {
   "source": [
    "Crie um tensor de formato $(5,3)$ no qual todos os elementos são o número 1, depois utilize o método `.shape` para verificar seu formato:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor: \n ...\nFormato: ...\n"
     ]
    }
   ],
   "source": [
    "tensor_de_uns = \"...\"\n",
    "formato_do_tensor = \"...\"\n",
    "\n",
    "print(f\"Tensor: \\n {tensor_de_uns}\")\n",
    "print(f\"Formato: {formato_do_tensor}\")"
   ]
  },
  {
   "source": [
    "Converta o *array* numpy para um tesnor de pytorch, depois transforme o tesnor em um *array* numpy novamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... \n É um tensor? False\n... \n É um array numpy? False\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,1,2,3], [5,8,13,21]])\n",
    "\n",
    "de_numpy_para_tensor = \"...\"\n",
    "print(f\"{de_numpy_para_tensor} \\n É um tensor? {isinstance(de_numpy_para_tensor, torch.Tensor)}\")\n",
    "\n",
    "de_tensor_para_numpy = \"...\"\n",
    "print(f\"{de_tensor_para_numpy} \\n É um array numpy? {isinstance(de_tensor_para_numpy, np.ndarray)}\")"
   ]
  },
  {
   "source": [
    "Complete a célula abaixo com as operações indicadas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Soma: ... \nSubtração: ... \nMultiplicação: ... \nDivisão: ... \nMédia: ... \nDesvio Padrão: ... \n\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.Tensor([[5,8],[5,4]])\n",
    "tensor_b = torch.Tensor([[10,16],[10,8]])\n",
    "\n",
    "soma = \"...\" # a+b\n",
    "subtracao = \"...\" # b-a\n",
    "mul = \"...\" # a*b\n",
    "div = \"...\" # b/a\n",
    "media = \"...\" # media de a\n",
    "std = \"...\" # desvio padrão de b\n",
    "\n",
    "print(f\"Soma: {soma} \\n\"\n",
    "      f\"Subtração: {subtracao} \\n\"\n",
    "      f\"Multiplicação: {mul} \\n\"\n",
    "      f\"Divisão: {div} \\n\"\n",
    "      f\"Média: {media} \\n\"\n",
    "      f\"Desvio Padrão: {std} \\n\")"
   ]
  },
  {
   "source": [
    "Crie uma **Varíavel** do pytorch com o tensor definido. Depois defina as equações $y = log_e(x)$ e $f(y) = 2*media(y)$. Para então aplicar a *backpropagation* em $f(x)$ e calcular seus gradientes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " x = ...\n y = ...\n f = ...\nComplete o exerćicio!\n"
     ]
    }
   ],
   "source": [
    "array = [4,5]\n",
    "tensor = torch.Tensor(array)\n",
    "\n",
    "x = \"...\"\n",
    "print(f\" x = {x}\")\n",
    "\n",
    "y = \"...\" # Dica: use o operador torch.log()\n",
    "print(f\" y = {y}\")\n",
    "\n",
    "f = \"...\"\n",
    "print(f\" f = {f}\")\n",
    "\n",
    "# Escreva aqui a backpropagation de f\n",
    "\n",
    "if isinstance(x, torch.Tensor): print(f\"Gradientes: {x.grad}\")\n",
    "else: print(\"Complete o exerćicio!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}