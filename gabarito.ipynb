{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('torch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a5cd74ba85a3b6a037c59ac3f3634fcdd9437555c9fe253dd51f04000fcd493e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Workshop Redes Neurais\n",
    "## Grupo Turing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Proposta de roteiro para o nb (deletar depois)\n",
    "\n",
    "#### O que deve ser falado antes do nb?\n",
    "- Introdução à redes neurais\n",
    "- estrutura geral de uma rede neural (talvez falar que é parecido com uma regressão logística?)\n",
    "- computation graph (talvez?)\n",
    "- forward propagation\n",
    "- back propagation (se falar de fp acho que é a sequência lógica)\n",
    "- optimizaçaõ e gradient descent\n",
    "\n",
    "#### Conteúdos do nb\n",
    "- Básico de Pytorch\n",
    "  - comparação com np\n",
    "  - operações básicas\n",
    "  - Variables (falar de back propagation?)\n",
    "- Implementando uma NN\n",
    "  - Implementar uma regressão logística (?)\n",
    "  - Implementar NN\n",
    "  - Falar sobre CNN e LSTM (?)\n",
    "  \n",
    "**Obs: ** Ainda é preciso deixar o NB mais bonito, mais imagens e talvez melhorar a estrura dos exemplos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Básicos de Pytorch\n",
    "\n",
    "Primeiro vamos ver alguns análogos entre **numpy** e **Pytorch**\n",
    "\n",
    "### Matrizes\n",
    " - Em Pytorch, matrizes (*arrays*) são chamados de tensores.\n",
    " - Uma matriz $3\\times3$, por exemplo é um tensor $3\\times3$\n",
    " - Podemos criar um array numpy com o método `np.numpy()`\n",
    " - Podemos pegar o tipo do array com `type()`\n",
    " - Podemos pegar o formato do *array* com `np.shape()`. Linha $\\times$ Coluna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array do tipo: <class 'numpy.ndarray'>\nArray de formato: (2, 3)\n[[1 2 3]\n [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "array = [[1,2,3],[4,5,6]]\n",
    "primeiro_array = np.array(array) # array 2x3\n",
    "print(f\"Array do tipo: {type(primeiro_array)}\")\n",
    "print(f\"Array de formato: {np.shape(primeiro_array)}\")\n",
    "print(primeiro_array)"
   ]
  },
  {
   "source": [
    "- Criamos um tensor com o método `torch.Tensor()`\n",
    "- `tensor.type`: tipo do *array*, nesse caso um tensor\n",
    "- `tensor.shape`: formato do *array*. Linha $\\times$ Coluna "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Array do tipo: <built-in method type of Tensor object at 0x7fcc33f6b1c0>\nArray de formato: torch.Size([2, 3])\ntensor([[1., 2., 3.],\n        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.Tensor(array)\n",
    "print(f\"Array do tipo: {tensor.type}\")\n",
    "print(f\"Array de formato: {tensor.shape}\")\n",
    "print(tensor)"
   ]
  },
  {
   "source": [
    "Podemos fazer a alocação de *arrays* de maneira análoga nas duas linguagens:\n",
    " - `np.ones()` = `torch.ones()`\n",
    " - `np.random.rand()` = `torch.rand()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy:\n [[1. 1. 1.]\n [1. 1. 1.]]\n\ntensor([[1., 1., 1.],\n        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numpy:\\n {np.ones((2,3))}\\n\")\n",
    "\n",
    "print(torch.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy:\n [[0.82725762 0.1715352  0.27674921]\n [0.28980857 0.4825568  0.94322397]]\n\ntensor([[0.1335, 0.9455, 0.0791],\n        [0.9499, 0.2731, 0.4527]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numpy:\\n {np.random.rand(2,3)}\\n\")\n",
    "\n",
    "print(torch.rand(2,3))"
   ]
  },
  {
   "source": [
    "### Convertendo de numpy para torch e vice-versa\n",
    "\n",
    "Em muitos pontos **numpy** e **pytorch** são bem parecidos em suas estruturas, e muitas das vezes podemos utilizar os dois em conjunto. Assim normalmente convertemos resultados de redes neurais - que são tensores - para **arrays** de **numpy**.\n",
    "\n",
    "Os métodos para fazer a conversão entre tensores e arrays numpy:\n",
    " - `torch.from_numpy()`: de um array numpy para um tensore\n",
    " - `numpy()`: de um tensor para um array numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'> \n [[0.09351619 0.99599026]\n [0.73997206 0.85712222]] \n\ntensor([[0.0935, 0.9960],\n        [0.7400, 0.8571]], dtype=torch.float64) \n\n<class 'numpy.ndarray'> \n [[0.09351619 0.99599026]\n [0.73997206 0.85712222]]\n"
     ]
    }
   ],
   "source": [
    "array = np.random.rand(2,2)\n",
    "print(f\"{type(array)} \\n {array} \\n\")\n",
    "\n",
    "de_numpy_para_tensor = torch.from_numpy(array)\n",
    "print(f\"{de_numpy_para_tensor} \\n\")\n",
    "\n",
    "tensor = de_numpy_para_tensor\n",
    "de_tensor_para_numpy = tensor.numpy()\n",
    "print(f\"{type(de_tensor_para_numpy)} \\n {de_tensor_para_numpy}\")"
   ]
  },
  {
   "source": [
    "Quando fazemos estas conversões também podemos fazer um *typecast* (mudagem do tipo) das variáveis, isso pode ser útil já que o Pytorch faz uma série de computações de baixo nível, o qual o tipo primitivo das variáveis precisa ser bem especificado e definido, para isso podemos usar o método `tensor.type(torch.TipoDeTensor)`, alguns tipode de tensores nativos do Pytorch são:\n",
    "  - `torch.FloatTensor` - pontos flutuantes de 32-bits\n",
    "  - `torch.DoubleTensor` - pontos flutuantes de 64-bits\n",
    "  - `torch.IntTensor` - números inteiros de 32-bits\n",
    "  - `torch.LongTensor` - númeos inteiros de 64-bits\n",
    "É muito comum encontrarmos *bugs* causados pela utilização errada de algum tipo primitivo, você pode ler sobre todos eles na [documentação do Pytorch](https://pytorch.org/docs/stable/tensors.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'> \n tensor([[ 1., 10.],\n        [ 2., 20.]])\n\n<class 'torch.Tensor'> \n tensor([[ 1, 10],\n        [ 2, 20]])\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,10],[2,20]])\n",
    "\n",
    "# Transformar em um tensor de Floats:\n",
    "tensor_float = torch.from_numpy(array).type(torch.FloatTensor)\n",
    "print(f\"{type(tensor_float)} \\n {tensor_float}\\n\")\n",
    "\n",
    "# Transformar em um tensor de Longs:\n",
    "tensor_long = torch.from_numpy(array).type(torch.LongTensor)\n",
    "print(f\"{type(tensor_long)} \\n {tensor_long}\")"
   ]
  },
  {
   "source": [
    "### Matemática básica com Pytorch\n",
    "*considere a e b dois tensores*\n",
    "\n",
    "- Redefinir o tamanho: `view()`\n",
    "- Adição: `torch.add(a,b)` = a + b\n",
    "- Subtração: `a.sub(b)` = a - b\n",
    "- Multiplicação elemento-a-elemento = `torch.mul(a,b)` = a * b\n",
    "- Divisão elemento-a-elemento = torch.div(a,b) = a / b\n",
    "- Média: a.mean()\n",
    "- Desvio Padrão (Standart Deviantion - std): a.std()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\ntorch.Size([9]): tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]) \n\nAdição: \ntensor([[2., 2., 2.],\n        [2., 2., 2.],\n        [2., 2., 2.]]) \n\nSubtração: \ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]]) \n\nMultiplicação elemento-a-elemento: \ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\nDivisão elemento-a-elemento: \ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]]) \n\nMédia: 3.0 \n\nDesvio padrão: 1.5811388492584229 \n\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(3,3)\n",
    "print(\"\\n\", tensor, \"\\n\")\n",
    "\n",
    "print(f\"{tensor.view(9).shape}: {tensor.view(9)} \\n\")\n",
    "\n",
    "print(f\"Adição: \\n{torch.add(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Subtração: \\n{torch.sub(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Multiplicação elemento-a-elemento: \\n{torch.mul(tensor, tensor)} \\n\")\n",
    "\n",
    "print(f\"Divisão elemento-a-elemento: \\n{torch.div(tensor, tensor)} \\n\")\n",
    "\n",
    "tensor = torch.Tensor([1,2,3,4,5])\n",
    "print(f\"Média: {tensor.mean()} \\n\")\n",
    "\n",
    "print(f\"Desvio padrão: {tensor.std()} \\n\")"
   ]
  },
  {
   "source": [
    "### Variáveis\n",
    "\n",
    "- Acumulam os gradientes\n",
    "- Na rede neural utilizaremos pytorch. Como explicamos anteriormente nas, redes neurais os gradientes são calculados na *backpropagation*.\n",
    "- A diferença entre variáveis e tensores é a de que variáveis acumulam os gradientes\n",
    "- Também podemos fazer operações matemáticas com variáveis\n",
    "- Dessa maneira, se queremos fazer a *backpropagation* precisamos de variáveis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "var = Variable(torch.ones(3), requires_grad = True)\n",
    "var"
   ]
  },
  {
   "source": [
    "Vamos ver um exemplo de como as Variávies são utilizadas em uma *backpropagation*, com duas função $f(y) = \\sum y$, $y(x) = x^2$ e $x = (3,5)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " x = tensor([3., 5.], requires_grad=True)\n f =  34.0\nGradientes: tensor([ 6., 10.])\n"
     ]
    }
   ],
   "source": [
    "array = [3,5]\n",
    "tensor = torch.Tensor(array)\n",
    "x = Variable(tensor, requires_grad = True)\n",
    "y = x**2\n",
    "print(f\" x = {x}\")\n",
    "\n",
    "f = sum(y)\n",
    "print(f\" f =  {f}\")\n",
    "\n",
    "f.backward() # Realiza as derivadas parciais\n",
    "\n",
    "print(f\"Gradientes: {x.grad}\")"
   ]
  },
  {
   "source": [
    "Vamos explicar passo a passo quais foram as operações feitas pelo Pytorch:\n",
    "- Primeiro ele recebe os elementos do tensor e faz a primeira operação com eles $y_1 = 3^2 = 9$ e $y_2 = 5^2 = 25$\n",
    "- Agora ele soma o tensor, retornando assim um único valor escalar: $\\sum_i y_i = y_1 + y_2 = 9 + 25 = 34$\n",
    "- O gradiente é a derivada parcial de cada elemento, ou seja o gradiente \"1\" é a derivada relativa à $y_1$ e o gradiente \"2\" é relativo à $y_2$ \n",
    "- derivada relativa à $y_1$ é $\\frac{\\partial}{\\partial y_1}(3^2) = 2*3 = 6$\n",
    "- derivada relativa à $y_2$ é $\\frac{\\partial}{\\partial y_2}(5^2) = 2*5 = 10$\n",
    "- Assim ficamos com os gradientes $(6, 10)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercícios\n",
    "\n",
    "Coplete às células de código abaixo no campo indicado por \"...\":"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Crie um tensor com base no *array* dado:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'...'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "array = [[10,100,1000], [20,200,2000]]\n",
    "tensor = \"...\"\n",
    "tensor"
   ]
  },
  {
   "source": [
    "Crie um tensor de formato $(5,3)$ no qual todos os elementos são o número 1, depois utilize o método `.shape` para verificar seu formato:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensor: \n ...\nFormato: ...\n"
     ]
    }
   ],
   "source": [
    "tensor_de_uns = \"...\"\n",
    "formato_do_tensor = \"...\"\n",
    "\n",
    "print(f\"Tensor: \\n {tensor_de_uns}\")\n",
    "print(f\"Formato: {formato_do_tensor}\")"
   ]
  },
  {
   "source": [
    "Converta o *array* numpy para um tesnor de pytorch, depois transforme o tesnor em um *array* numpy novamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "... \n É um tensor? False\n... \n É um array numpy? False\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,1,2,3], [5,8,13,21]])\n",
    "\n",
    "de_numpy_para_tensor = \"...\"\n",
    "print(f\"{de_numpy_para_tensor} \\n É um tensor? {isinstance(de_numpy_para_tensor, torch.Tensor)}\")\n",
    "\n",
    "de_tensor_para_numpy = \"...\"\n",
    "print(f\"{de_tensor_para_numpy} \\n É um array numpy? {isinstance(de_tensor_para_numpy, np.ndarray)}\")"
   ]
  },
  {
   "source": [
    "Complete a célula abaixo com as operações indicadas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Soma: ... \nSubtração: ... \nMultiplicação: ... \nDivisão: ... \nMédia: ... \nDesvio Padrão: ... \n\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.Tensor([[5,8],[5,4]])\n",
    "tensor_b = torch.Tensor([[10,16],[10,8]])\n",
    "\n",
    "soma = \"...\" # a+b\n",
    "subtracao = \"...\" # b-a\n",
    "mul = \"...\" # a*b\n",
    "div = \"...\" # b/a\n",
    "media = \"...\" # media de a\n",
    "std = \"...\" # desvio padrão de b\n",
    "\n",
    "print(f\"Soma: {soma} \\n\"\n",
    "      f\"Subtração: {subtracao} \\n\"\n",
    "      f\"Multiplicação: {mul} \\n\"\n",
    "      f\"Divisão: {div} \\n\"\n",
    "      f\"Média: {media} \\n\"\n",
    "      f\"Desvio Padrão: {std} \\n\")"
   ]
  },
  {
   "source": [
    "Crie uma **Varíavel** do pytorch com o tensor definido. Depois defina as equações $y = log_e(x)$ e $f(y) = 2*media(y)$. Para então aplicar a *backpropagation* em $f(x)$ e calcular seus gradientes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " x = ...\n y = ...\n f = ...\nComplete o exerćicio!\n"
     ]
    }
   ],
   "source": [
    "array = [4,5]\n",
    "tensor = torch.Tensor(array)\n",
    "\n",
    "x = \"...\"\n",
    "print(f\" x = {x}\")\n",
    "\n",
    "y = \"...\" # Dica: use o operador torch.log()\n",
    "print(f\" y = {y}\")\n",
    "\n",
    "f = \"...\"\n",
    "print(f\" f = {f}\")\n",
    "\n",
    "# Escreva aqui a backpropagation de f\n",
    "\n",
    "if isinstance(x, torch.Tensor): print(f\"Gradientes: {x.grad}\")\n",
    "else: print(\"Complete o exerćicio!\")"
   ]
  },
  {
   "source": [
    "## Implementando uma rede neural\n",
    "### Conhecendo e preparando nossos dados \n",
    "\n",
    "**[Fashion MNIST](https://www.kaggle.com/zalando-research/fashionmnist)** é uma coleção de diversas peças de roupas retiradas do serviço de *e-commerce* Zalando, ele consiste de cerca de 60.000 entradas de treino de 10.000 de teste. Cada entrada é uma imagem de 28x28 pixels em escala cinza. As peças de roupa estão classificadas da seguinte maneira:\n",
    "  - 0 *T-shirt*\n",
    "  - 1 *Trouser*\n",
    "  - 2 *Pullover*\n",
    "  - 3 *Dress*\n",
    "  - 4 *Coat*\n",
    "  - 5 *Sandal*\n",
    "  - 6 *Shirt*\n",
    "  - 7 *Sneaker*\n",
    "  - 8 *Bag*\n",
    "  - 9 *Ankle boot*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_inicial = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "df_inicial.head() # Como cada coluna representa o valor de cada pixel, a tabela dos dados não é muito \"emocionante\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Número de entradas de treino: 50000\nNúmero de entradas de validação: 10000\n"
     ]
    }
   ],
   "source": [
    "n_validos = 10000\n",
    "n_treino = len(df_inicial) - n_validos\n",
    "print(f\"Número de entradas de treino: {n_treino}\\n\"\n",
    "      f\"Número de entradas de validação: {n_validos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos essa função para dividir entre dados de treino e validação\n",
    "def divide_valores(a,n):\n",
    "     return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dataset entre dados x e labels y\n",
    "y, x = df_inicial[\"label\"].values, df_inicial.loc[:, df_inicial.columns != \"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_valido = divide_valores(x, n_treino)\n",
    "y_treino, y_valido = divide_valores(y, n_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Formato do x de treino: (50000, 784)\nFormato do x de validação: (10000, 784)\nFormato do y de treino: (50000,)\nFormato do y de validação: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Formato do x de treino: {x_treino.shape}\\n\"\n",
    "      f\"Formato do x de validação: {x_valido.shape}\\n\"\n",
    "      f\"Formato do y de treino: {y_treino.shape}\\n\"\n",
    "      f\"Formato do y de validação: {y_valido.shape}\")"
   ]
  },
  {
   "source": [
    "Uma etapa comum de pré processamento de dados em aprendizado por máquina é centralizar padronizar nosso *dataset*, o que isso basicamente significa é que iremos subtrair a média de todo o *dataset* e dividi-lo pelo seu desvio padrão. Esse processo ajuda a agilizar o processo de aprendizado."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Média antes do pré processamento: 72.86\nDesvio padrão antes do pré processamente: 89.89\nMédia depois do pré processamento: -0.00\nDesvio padrão depois do pré processamento: 1.00\n"
     ]
    }
   ],
   "source": [
    "media = x_treino.mean()\n",
    "desvio_padrao = x_treino.std()\n",
    "\n",
    "x_treino = (x_treino-media)/desvio_padrao\n",
    "print(f\"Média antes do pré processamento: {media:.2f}\\n\"\n",
    "      f\"Desvio padrão antes do pré processamente: {desvio_padrao:.2f}\\n\"\n",
    "      f\"Média depois do pré processamento: {x_treino.mean():.2f}\\n\"\n",
    "      f\"Desvio padrão depois do pré processamento: {x_treino.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Média pós processamento: 0.01\nDesvio padrão pós processamento: 1.01\n"
     ]
    }
   ],
   "source": [
    "# O mesmo deve ser feito com a validação\n",
    "\n",
    "x_valido = (x_valido-media)/desvio_padrao\n",
    "print(f\"Média pós processamento: {x_valido.mean():.2f}\\n\"\n",
    "      f\"Desvio padrão pós processamento: {x_valido.std():.2f}\")"
   ]
  },
  {
   "source": [
    "Vamos visualizar algumas das imagens de nosso *dataset*:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Essa função vai nos ajudar a visualizar as imagens\n",
    "def mostrar(img, title=None):\n",
    "    labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    if title is not None: plt.title(labels[int(title)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 251.565 263.63625\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-20T19:46:41.301470</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 263.63625 \nL 251.565 263.63625 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 239.758125 \nL 244.365 239.758125 \nL 244.365 22.318125 \nL 26.925 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pfd5d58bdfe)\">\n    <image height=\"218\" id=\"image43ad557d2e\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-21.758125\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"md0406a2590\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(27.626607 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(66.455179 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(102.1025 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(179.759643 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#md0406a2590\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9d87daa45c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"26.200982\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 30.000201)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"65.029554\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 68.828772)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"103.858125\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 107.657344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"142.686696\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 146.485915)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"181.515268\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 185.314487)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m9d87daa45c\" y=\"220.343839\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 224.143058)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 239.758125 \nL 26.925 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 239.758125 \nL 244.365 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 239.758125 \nL 244.365 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 22.318125 \nL 244.365 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_13\">\n    <!-- Pullover -->\n    <g transform=\"translate(111.615 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-80\"/>\n     <use x=\"58.552734\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"121.931641\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"149.714844\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"177.498047\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"238.679688\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"297.859375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"359.382812\" xlink:href=\"#DejaVuSans-114\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfd5d58bdfe\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "x_imgs = np.reshape(x_valido, (-1, 28, 28))\n",
    "\n",
    "index = 100\n",
    "mostrar(x_imgs[index], y_valido[index])"
   ]
  },
  {
   "source": [
    "### Começando com uma regressão logística\n",
    "\n",
    "Dizemos que uma regressão linear é basicamente uma maneira de visualizar nossos dados em uma \"linha\" e que a partir dessa linha podemos fazer algumas predições sobre dados futuros.\n",
    "\n",
    "Porém, regressões lineares não são muito boas com classificações, para isso utilizaremos uma regressão logística.\n",
    "\n",
    "Uma regressão logística é uma regressão linear que utiliza a função **softmax** como uma **função de ativação**:\n",
    "$$\n",
    "a_i = \\frac{e^{x+i}}{\\sum_{j=1}^n e^{x_j}}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "> **Obs:** O que a função **softmax** basicamente faz é receber um vetor (lista) de valores numéricos e os transforma em valores probabilísticos. Em outras palavras, quanto maior for o valor da preferência daquela patâmetro, depois que essa lista de valores passar pela função Softmax, maior será sua probabilidade."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "É interessante primeiro estudarmos a regressão logística antes de vermos uma rede neural pois a regressão logística é basicamente uma rede neural simples!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![Grafo de Regressão logística](./imgs/diagrama_logreg.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressaoLogistica(nn.Module):\n",
    "    def __init__ (self, input_dim, output_dim):\n",
    "        super(RegressaoLogistica, self).__init__()  # Já que será \"filho\" de nn.Module, temos que iniciar seu \"pai\"\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim), # Parte linear\n",
    "            nn.LogSoftmax()                   # A parte logística\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "\n",
    "erro = nn.NLLLoss() # Função de perda (loss)\n",
    "\n",
    "input_dim = 28*28 # Dica, olhe na especificação do problema\n",
    "output_dim = 10\n",
    "\n",
    "# Inicialize a Regressão Logística com as dimensões de input e output estabelecidas\n",
    "modelo = RegressaoLogistica(input_dim, output_dim) \n",
    "\n",
    "# Aqui escolhemos nosso optimizador, que nesse caso será o Stochastic gradient descent, \n",
    "# que estará optimizando os parâmetros de nossa regrssão linear.\n",
    "taxa_aprendizado = 0.001\n",
    "optmizador = torch.optim.SGD(modelo.parameters(), lr=taxa_aprendizado)"
   ]
  },
  {
   "source": [
    "Vamos agora treinar nosso modelo:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforme os respectivos datasets de numpy para tensores torch, \n",
    "# o tensor x_treino_torch deve ser do tipo torch.FloatTensor\n",
    "# Dica, lembre-se da seção \"Convertendo de numpy para torch e vice-versa\"\n",
    "x_treino_torch = torch.from_numpy(x_treino).type(torch.FloatTensor)\n",
    "y_treino_torch = torch.from_numpy(y_treino)\n",
    "\n",
    "x_valido_torch = torch.from_numpy(x_valido).type(torch.FloatTensor)\n",
    "y_valido_torch = torch.from_numpy(y_valido)\n",
    "\n",
    "tamanho_batch = 100\n",
    "n_iters = 10000\n",
    "\n",
    "n_epochs = int((n_iters / len(y_treino)) * tamanho_batch)\n",
    "\n",
    "# Transformamos em um dataset de tensores\n",
    "treino = torch.utils.data.TensorDataset(x_treino_torch, y_treino_torch)\n",
    "validacao = torch.utils.data.TensorDataset(x_valido_torch, y_valido_torch)\n",
    "\n",
    "# Preparamos o dataser para ser iterado pela rede\n",
    "treino_loader = DataLoader(treino, batch_size=tamanho_batch, shuffle=False)\n",
    "validacao_loader = DataLoader(validacao, batch_size=tamanho_batch, shuffle=False)"
   ]
  },
  {
   "source": [
    "### Para que serviu o TensorDataset e o DataLoader?\n",
    "\n",
    "Basicamente, o que eles fazem é transformar nosso conjunto de tensores (que antes eram arrays numpy) em algo iterável, ou seja, que podemos percorrer por com um loop, além disso, já os dividimos em levas (*batchs*) de 100 serão alimentados na nossa rede. Vamos dar uma olhada em como está estruturado nosso `treino_loader`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([7, 6, 3, 4, 4, 9, 7, 9, 6, 5, 7, 4, 4, 7, 9, 1, 6, 9, 4, 7, 5, 4, 0, 9,\n",
      "        0, 1, 5, 8, 7, 6, 5, 4, 1, 2, 9, 5, 0, 6, 3, 2, 5, 7, 3, 5, 1, 9, 1, 0,\n",
      "        6, 4, 8, 8, 5, 0, 8, 2, 4, 3, 7, 2, 1, 4, 2, 8, 1, 9, 0, 9, 7, 3, 5, 9,\n",
      "        4, 9, 3, 2, 9, 4, 4, 6, 3, 9, 8, 6, 4, 8, 1, 5, 8, 2, 1, 6, 0, 9, 1, 3,\n",
      "        2, 9, 8, 4])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ...,  0.3575, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([3, 6, 1, 8, 1, 9, 3, 3, 5, 3, 7, 7, 0, 1, 2, 2, 9, 1, 0, 5, 2, 2, 6, 3,\n",
      "        0, 5, 2, 8, 6, 5, 3, 0, 7, 2, 2, 0, 4, 6, 5, 1, 3, 4, 7, 0, 3, 4, 7, 3,\n",
      "        5, 2, 8, 8, 7, 0, 1, 1, 1, 3, 7, 9, 5, 7, 0, 2, 4, 6, 2, 4, 0, 2, 8, 0,\n",
      "        7, 4, 1, 3, 2, 7, 9, 9, 0, 7, 6, 0, 3, 8, 2, 5, 0, 5, 9, 3, 8, 8, 7, 1,\n",
      "        6, 1, 2, 3])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.7883,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([0, 5, 0, 6, 0, 5, 3, 6, 6, 3, 1, 4, 4, 0, 9, 0, 7, 5, 7, 8, 9, 4, 6, 9,\n",
      "        9, 6, 6, 0, 8, 7, 7, 8, 4, 2, 8, 2, 3, 5, 3, 7, 3, 6, 3, 1, 2, 4, 0, 1,\n",
      "        7, 6, 2, 7, 7, 4, 9, 0, 6, 6, 1, 7, 4, 8, 4, 0, 4, 8, 5, 7, 0, 6, 1, 2,\n",
      "        3, 1, 2, 2, 6, 2, 8, 3, 9, 7, 8, 9, 3, 7, 0, 2, 5, 8, 0, 5, 6, 9, 1, 3,\n",
      "        2, 3, 8, 6])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([4, 9, 0, 8, 1, 0, 5, 7, 0, 7, 3, 9, 7, 5, 7, 7, 3, 1, 0, 4, 8, 4, 5, 9,\n",
      "        5, 8, 2, 8, 6, 5, 6, 7, 8, 8, 2, 7, 4, 9, 4, 9, 2, 0, 1, 7, 9, 1, 1, 0,\n",
      "        1, 7, 9, 4, 6, 0, 3, 4, 4, 2, 8, 7, 9, 3, 5, 2, 6, 5, 5, 1, 5, 5, 6, 9,\n",
      "        7, 6, 5, 1, 6, 3, 6, 9, 6, 3, 6, 1, 2, 2, 5, 4, 4, 3, 8, 0, 5, 2, 0, 1,\n",
      "        3, 3, 8, 6])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([2, 9, 7, 8, 5, 8, 8, 0, 4, 8, 2, 1, 5, 8, 4, 4, 6, 8, 6, 9, 3, 7, 2, 3,\n",
      "        3, 0, 3, 0, 7, 5, 1, 0, 3, 4, 7, 9, 7, 1, 6, 6, 9, 2, 0, 6, 5, 4, 3, 6,\n",
      "        5, 1, 4, 9, 9, 1, 3, 0, 4, 4, 2, 8, 8, 6, 4, 6, 1, 9, 9, 8, 4, 8, 5, 8,\n",
      "        4, 2, 5, 5, 4, 7, 3, 9, 4, 9, 4, 0, 9, 8, 4, 3, 2, 5, 7, 9, 0, 1, 2, 4,\n",
      "        5, 5, 9, 9])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([3, 7, 3, 1, 6, 1, 7, 1, 0, 5, 9, 7, 0, 4, 1, 1, 7, 7, 8, 6, 7, 0, 1, 1,\n",
      "        9, 9, 4, 1, 2, 4, 0, 0, 4, 7, 6, 3, 0, 9, 1, 9, 1, 4, 6, 4, 8, 7, 1, 4,\n",
      "        9, 4, 0, 9, 9, 9, 0, 7, 3, 7, 9, 4, 4, 9, 0, 9, 3, 1, 4, 9, 0, 5, 5, 6,\n",
      "        7, 3, 0, 3, 0, 5, 2, 2, 0, 2, 9, 8, 8, 8, 9, 8, 2, 3, 4, 5, 8, 0, 2, 6,\n",
      "        1, 6, 1, 7])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([7, 7, 1, 0, 4, 6, 0, 6, 1, 5, 9, 0, 2, 8, 2, 3, 8, 2, 7, 8, 5, 7, 5, 5,\n",
      "        2, 8, 2, 4, 5, 9, 6, 2, 8, 2, 1, 8, 7, 0, 3, 5, 7, 8, 1, 8, 6, 2, 4, 0,\n",
      "        3, 6, 8, 3, 2, 4, 8, 6, 3, 3, 0, 6, 5, 9, 8, 0, 4, 6, 9, 8, 2, 0, 3, 9,\n",
      "        1, 6, 9, 8, 9, 3, 4, 3, 0, 3, 1, 3, 2, 3, 9, 3, 7, 7, 8, 2, 1, 1, 3, 7,\n",
      "        1, 9, 9, 2])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([7, 2, 4, 4, 9, 1, 6, 7, 0, 9, 7, 4, 6, 0, 9, 1, 1, 2, 5, 2, 4, 0, 9, 8,\n",
      "        5, 3, 7, 2, 8, 2, 0, 5, 9, 8, 8, 8, 6, 2, 3, 1, 9, 3, 4, 4, 0, 4, 7, 1,\n",
      "        1, 5, 2, 2, 2, 0, 7, 8, 4, 6, 0, 0, 7, 4, 7, 7, 7, 1, 8, 3, 7, 0, 5, 2,\n",
      "        7, 7, 6, 6, 0, 0, 9, 6, 1, 7, 5, 6, 5, 7, 4, 9, 4, 6, 2, 9, 0, 4, 5, 8,\n",
      "        1, 7, 8, 1])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([5, 4, 5, 9, 7, 7, 6, 9, 5, 7, 0, 2, 2, 6, 5, 0, 1, 1, 5, 5, 3, 5, 8, 7,\n",
      "        4, 2, 5, 9, 3, 2, 1, 2, 2, 6, 9, 1, 3, 4, 0, 6, 9, 3, 8, 6, 7, 3, 9, 1,\n",
      "        1, 4, 2, 3, 7, 5, 9, 8, 1, 1, 1, 5, 9, 5, 3, 7, 4, 7, 5, 3, 0, 0, 1, 4,\n",
      "        1, 1, 6, 6, 4, 8, 7, 2, 6, 2, 1, 7, 3, 2, 4, 7, 2, 5, 9, 1, 4, 0, 7, 6,\n",
      "        6, 6, 7, 4])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.3545, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([7, 0, 7, 4, 4, 6, 8, 1, 3, 5, 5, 8, 7, 7, 4, 4, 3, 6, 8, 0, 2, 0, 6, 6,\n",
      "        9, 6, 8, 3, 1, 4, 7, 1, 1, 2, 3, 7, 2, 0, 6, 3, 7, 1, 9, 0, 4, 0, 6, 7,\n",
      "        8, 5, 2, 1, 3, 5, 8, 2, 8, 6, 9, 0, 7, 6, 2, 4, 4, 2, 3, 1, 2, 7, 9, 4,\n",
      "        5, 3, 2, 1, 5, 3, 4, 9, 6, 1, 7, 7, 9, 8, 6, 7, 3, 1, 2, 4, 9, 4, 0, 1,\n",
      "        2, 6, 4, 2])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([5, 1, 7, 1, 4, 9, 0, 8, 1, 9, 4, 9, 7, 5, 2, 6, 5, 1, 0, 8, 6, 1, 8, 8,\n",
      "        4, 1, 2, 1, 1, 3, 0, 8, 3, 3, 9, 2, 9, 1, 2, 7, 4, 0, 9, 5, 2, 5, 5, 7,\n",
      "        9, 3, 1, 2, 9, 6, 4, 0, 2, 2, 6, 8, 3, 4, 0, 0, 4, 2, 7, 5, 9, 4, 6, 5,\n",
      "        0, 3, 0, 4, 0, 9, 3, 0, 6, 7, 0, 6, 3, 3, 8, 6, 4, 1, 7, 5, 5, 6, 5, 7,\n",
      "        1, 9, 0, 8])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([0, 6, 2, 3, 9, 2, 4, 8, 0, 4, 1, 3, 5, 3, 4, 1, 2, 4, 4, 4, 8, 1, 3, 3,\n",
      "        5, 3, 6, 5, 1, 6, 4, 2, 5, 6, 0, 8, 5, 6, 5, 6, 1, 4, 8, 5, 3, 7, 4, 6,\n",
      "        2, 5, 1, 1, 2, 9, 5, 1, 1, 3, 8, 9, 8, 7, 4, 5, 1, 7, 3, 4, 5, 2, 9, 6,\n",
      "        5, 7, 9, 9, 1, 6, 9, 5, 3, 4, 9, 5, 0, 7, 2, 0, 4, 5, 0, 9, 7, 5, 6, 4,\n",
      "        8, 7, 4, 7])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([5, 8, 2, 2, 9, 8, 5, 5, 1, 3, 5, 0, 2, 7, 9, 1, 2, 5, 2, 3, 9, 1, 5, 8,\n",
      "        3, 2, 8, 3, 3, 8, 0, 2, 7, 8, 7, 9, 1, 6, 2, 5, 8, 8, 4, 1, 9, 8, 4, 1,\n",
      "        6, 5, 1, 7, 2, 5, 3, 6, 7, 9, 6, 6, 8, 0, 5, 2, 5, 3, 2, 6, 1, 5, 9, 7,\n",
      "        5, 9, 4, 2, 3, 7, 2, 1, 6, 4, 4, 1, 2, 2, 3, 9, 8, 4, 8, 9, 1, 6, 3, 6,\n",
      "        1, 5, 4, 3])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ...,  0.7246, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([2, 5, 8, 2, 9, 0, 8, 9, 0, 9, 7, 4, 1, 8, 9, 9, 9, 7, 9, 1, 1, 5, 3, 6,\n",
      "        7, 0, 1, 7, 4, 1, 0, 8, 4, 8, 0, 7, 8, 7, 2, 0, 6, 9, 6, 0, 9, 2, 8, 9,\n",
      "        0, 5, 2, 7, 0, 6, 2, 0, 4, 4, 5, 3, 4, 3, 8, 4, 2, 0, 2, 1, 1, 5, 5, 4,\n",
      "        6, 5, 7, 0, 8, 3, 5, 1, 4, 9, 4, 9, 8, 7, 1, 7, 6, 1, 1, 4, 5, 8, 6, 3,\n",
      "        5, 7, 3, 4])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([5, 4, 3, 4, 4, 2, 5, 4, 3, 8, 5, 4, 5, 8, 6, 5, 7, 5, 5, 5, 3, 5, 7, 7,\n",
      "        7, 2, 0, 4, 0, 5, 3, 0, 4, 6, 5, 0, 6, 3, 0, 3, 3, 4, 4, 4, 6, 9, 8, 6,\n",
      "        1, 9, 1, 1, 9, 5, 3, 0, 6, 5, 0, 6, 0, 0, 2, 2, 2, 6, 2, 7, 4, 8, 2, 1,\n",
      "        3, 7, 7, 8, 5, 6, 4, 2, 4, 7, 8, 7, 7, 1, 9, 0, 8, 0, 2, 1, 2, 3, 0, 4,\n",
      "        6, 8, 0, 9])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([2, 3, 1, 5, 7, 2, 6, 2, 5, 3, 3, 2, 4, 8, 7, 7, 1, 2, 6, 5, 5, 3, 4, 6,\n",
      "        9, 8, 2, 0, 8, 5, 9, 6, 9, 9, 7, 9, 6, 7, 7, 0, 3, 4, 9, 9, 6, 8, 5, 5,\n",
      "        0, 5, 0, 6, 9, 0, 8, 2, 6, 9, 3, 2, 4, 8, 7, 2, 2, 5, 9, 5, 4, 0, 8, 1,\n",
      "        1, 6, 9, 4, 5, 7, 4, 6, 4, 6, 4, 4, 0, 9, 6, 3, 1, 3, 2, 4, 0, 1, 1, 6,\n",
      "        2, 4, 9, 0])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([4, 1, 8, 6, 5, 7, 9, 2, 5, 1, 9, 1, 4, 1, 3, 7, 1, 1, 1, 6, 7, 9, 1, 0,\n",
      "        2, 5, 4, 2, 6, 9, 3, 4, 8, 5, 7, 2, 7, 4, 8, 4, 5, 3, 8, 9, 7, 8, 7, 4,\n",
      "        4, 0, 6, 4, 0, 7, 3, 0, 8, 1, 4, 4, 8, 8, 3, 3, 3, 3, 4, 5, 8, 3, 2, 8,\n",
      "        7, 9, 3, 3, 8, 6, 1, 5, 2, 1, 1, 7, 0, 8, 6, 5, 8, 7, 4, 1, 1, 4, 6, 5,\n",
      "        0, 0, 1, 2])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.7549, -0.6215, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([6, 7, 1, 0, 8, 5, 8, 9, 2, 7, 0, 1, 0, 8, 3, 4, 2, 4, 5, 2, 2, 3, 1, 8,\n",
      "        1, 7, 4, 9, 0, 9, 2, 4, 8, 5, 7, 7, 3, 6, 3, 0, 2, 1, 8, 2, 4, 5, 7, 2,\n",
      "        5, 0, 1, 0, 5, 5, 2, 7, 2, 3, 7, 4, 8, 8, 0, 7, 9, 7, 3, 2, 5, 1, 0, 2,\n",
      "        2, 2, 4, 4, 3, 1, 9, 3, 8, 1, 4, 2, 4, 4, 1, 9, 6, 2, 4, 2, 7, 0, 7, 5,\n",
      "        2, 2, 9, 7])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([9, 7, 6, 8, 2, 0, 3, 0, 9, 2, 3, 3, 6, 0, 4, 5, 5, 9, 0, 3, 0, 2, 8, 9,\n",
      "        4, 9, 5, 0, 8, 9, 2, 1, 8, 3, 0, 6, 2, 8, 5, 3, 5, 2, 5, 1, 9, 8, 3, 7,\n",
      "        9, 8, 0, 5, 1, 7, 3, 5, 0, 8, 3, 9, 9, 1, 5, 5, 2, 7, 0, 3, 4, 7, 6, 4,\n",
      "        9, 5, 9, 6, 4, 8, 3, 2, 8, 7, 6, 5, 8, 2, 4, 5, 5, 1, 2, 0, 0, 0, 9, 3,\n",
      "        9, 6, 8, 8])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.7994, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([1, 0, 1, 5, 9, 0, 9, 4, 1, 6, 3, 2, 1, 8, 7, 2, 5, 4, 1, 2, 6, 0, 7, 9,\n",
      "        0, 5, 2, 0, 9, 3, 5, 5, 4, 2, 1, 8, 9, 5, 3, 4, 4, 1, 9, 0, 4, 6, 1, 1,\n",
      "        9, 0, 9, 9, 3, 4, 9, 6, 2, 7, 9, 8, 4, 2, 6, 2, 7, 1, 4, 9, 3, 1, 5, 1,\n",
      "        5, 2, 6, 7, 0, 5, 9, 4, 1, 1, 4, 9, 9, 8, 5, 8, 0, 0, 9, 9, 3, 0, 1, 8,\n",
      "        5, 8, 8, 8])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([8, 1, 1, 9, 6, 2, 8, 1, 5, 5, 9, 6, 9, 2, 7, 4, 2, 3, 3, 0, 4, 9, 8, 8,\n",
      "        9, 6, 2, 4, 2, 9, 3, 7, 2, 2, 1, 6, 1, 0, 8, 6, 5, 1, 4, 0, 6, 3, 9, 8,\n",
      "        9, 9, 0, 3, 0, 1, 0, 0, 4, 3, 3, 8, 1, 1, 8, 3, 2, 7, 2, 2, 3, 3, 7, 6,\n",
      "        2, 2, 8, 5, 8, 4, 8, 9, 0, 7, 7, 8, 7, 1, 9, 4, 7, 1, 6, 2, 5, 3, 3, 4,\n",
      "        3, 3, 2, 1])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ...,  0.0238, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([4, 2, 4, 6, 3, 6, 2, 5, 0, 0, 9, 0, 6, 0, 4, 3, 8, 0, 9, 5, 0, 8, 0, 6,\n",
      "        0, 1, 3, 2, 0, 3, 7, 8, 8, 1, 0, 1, 8, 9, 6, 3, 3, 2, 4, 9, 0, 6, 9, 9,\n",
      "        8, 3, 5, 4, 9, 4, 5, 7, 6, 1, 0, 7, 1, 2, 8, 4, 1, 7, 9, 9, 7, 4, 6, 6,\n",
      "        9, 4, 4, 4, 8, 2, 0, 7, 5, 2, 5, 8, 7, 7, 5, 0, 6, 3, 4, 8, 5, 3, 8, 1,\n",
      "        3, 4, 4, 3])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([8, 2, 1, 3, 7, 1, 1, 9, 4, 6, 7, 2, 2, 9, 7, 8, 8, 0, 6, 7, 5, 4, 5, 7,\n",
      "        1, 4, 7, 6, 0, 3, 0, 2, 0, 1, 4, 3, 8, 9, 8, 4, 0, 3, 0, 4, 6, 6, 9, 6,\n",
      "        9, 6, 4, 1, 3, 6, 8, 9, 7, 3, 2, 5, 1, 8, 0, 5, 1, 5, 9, 2, 2, 6, 7, 4,\n",
      "        6, 1, 0, 8, 8, 3, 4, 1, 0, 5, 1, 9, 3, 2, 8, 0, 4, 3, 3, 6, 4, 1, 8, 8,\n",
      "        9, 1, 4, 1])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([6, 0, 6, 2, 1, 2, 2, 1, 5, 2, 6, 4, 4, 0, 3, 8, 6, 8, 7, 9, 3, 4, 3, 3,\n",
      "        8, 8, 3, 7, 0, 0, 6, 9, 5, 5, 1, 2, 9, 0, 6, 6, 1, 2, 1, 5, 4, 3, 4, 1,\n",
      "        6, 8, 9, 8, 4, 3, 0, 5, 3, 0, 1, 2, 5, 2, 4, 3, 7, 1, 0, 7, 0, 1, 0, 2,\n",
      "        8, 1, 2, 6, 5, 6, 4, 1, 9, 4, 3, 4, 4, 1, 7, 8, 9, 0, 6, 9, 5, 7, 2, 7,\n",
      "        2, 4, 5, 2])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([2, 6, 8, 2, 9, 0, 8, 2, 6, 8, 0, 4, 8, 1, 9, 7, 5, 1, 8, 5, 2, 5, 3, 8,\n",
      "        9, 9, 5, 2, 6, 1, 7, 9, 7, 5, 6, 7, 9, 8, 5, 1, 9, 5, 6, 3, 7, 9, 0, 6,\n",
      "        2, 9, 0, 9, 6, 1, 7, 7, 1, 5, 2, 9, 2, 9, 4, 2, 0, 0, 3, 8, 0, 7, 0, 3,\n",
      "        4, 6, 1, 8, 4, 4, 6, 1, 0, 1, 2, 8, 8, 1, 1, 1, 2, 5, 9, 5, 8, 2, 1, 4,\n",
      "        5, 7, 0, 0])]\n",
      "[tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]]), tensor([8, 8, 7, 4, 2, 7, 2, 4, 1, 3, 0, 8, 4, 1, 6, 2, 8, 1, 2, 0, 9, 3, 8, 2,\n",
      "        7, 8, 2, 6, 2, 6, 2, 6, 4, 3, 7, 2, 9, 2, 4, 0, 0, 9, 3, 8, 0, 0, 7, 0,\n",
      "        3, 9, 2, 3, 2, 1, 9, 1, 3, 1, 6, 3, 2, 3, 2, 2, 0, 4, 9, 1, 1, 6, 8, 6,\n",
      "        1, 0, 0, 1, 5, 4, 1, 9, 4, 2, 2, 4, 2, 2, 6, 0, 7, 5, 6, 0, 6, 4, 9, 2,\n",
      "        9, 4, 4, 9])]\n"
     ]
    }
   ],
   "source": [
    "for i in treino_loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(treino_loader)"
   ]
  },
  {
   "source": [
    "Aqui podemos observar que nosso treino_loader é composto de 500 pares de tensores, vamos olhar melhor cada um desses tensores:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".4309e-01, -2.8771e-01, -7.8832e-01,  1.5727e-01, -3.6559e-01,\n",
      "        -6.6595e-01, -4.3233e-01, -8.1057e-01,  3.4639e-01,  2.3514e-01,\n",
      "        -4.2121e-01, -4.5458e-01,  1.4700e+00, -5.7695e-01,  6.8275e-02,\n",
      "        -6.6595e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -7.2157e-01, -7.7720e-01, -5.2133e-01,  5.4663e-01,\n",
      "        -3.0996e-01, -4.7683e-01, -5.2133e-01, -2.5434e-01, -6.2145e-01,\n",
      "         2.4627e-01,  9.9162e-01,  3.9089e-01, -9.8594e-02,  5.7150e-02,\n",
      "        -8.1057e-01, -4.8796e-01, -2.5434e-01, -6.7707e-01, -8.1057e-01,\n",
      "        -1.6534e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -4.7683e-01, -5.1021e-01,\n",
      "        -3.4334e-01, -1.9872e-01, -5.7695e-01,  3.4639e-01,  7.4688e-01,\n",
      "         7.8025e-01, -2.4321e-01, -2.9884e-01, -5.8808e-01, -5.8808e-01,\n",
      "        -5.1021e-01, -6.1033e-01, -7.4382e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -7.9945e-01, -7.9945e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -5.7695e-01, -1.6534e-01, -1.9872e-01, -1.9872e-01,\n",
      "         1.0806e+00,  6.6900e-01,  9.3600e-01,  1.1362e+00,  6.9125e-01,\n",
      "         2.1289e-01, -2.0984e-01, -7.5495e-01, -3.7671e-01, -4.7683e-01,\n",
      "        -7.7720e-01, -8.1057e-01, -7.9945e-01, -7.9945e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -5.6583e-01,\n",
      "        -2.0984e-01, -3.6559e-01,  5.9113e-01,  1.0361e+00,  4.7989e-01,\n",
      "         6.3563e-01,  1.0361e+00,  5.0214e-01,  3.0189e-01,  6.8275e-02,\n",
      "        -8.1057e-01, -4.3233e-01,  6.8275e-02, -6.6595e-01, -8.1057e-01,\n",
      "        -7.9945e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -7.9945e-01, -8.1057e-01, -5.6583e-01, -4.8796e-01, -5.1021e-01,\n",
      "         6.0226e-01,  3.7976e-01,  1.1277e-01,  8.8037e-01,  5.3551e-01,\n",
      "        -6.7707e-01, -4.7683e-01, -1.5422e-01, -6.9932e-01, -8.1057e-01,\n",
      "        -4.6571e-01, -5.1021e-01, -8.1057e-01, -7.8832e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -7.9945e-01, -8.1057e-01,\n",
      "        -7.3270e-01, -2.6546e-01, -1.3197e-01, -9.8594e-02, -2.0722e-02,\n",
      "         1.0165e-01,  8.3587e-01, -1.6534e-01, -4.8796e-01, -4.8796e-01,\n",
      "        -7.3270e-01, -1.9872e-01,  1.1277e-01, -1.6534e-01, -4.5458e-01,\n",
      "        -8.1057e-01, -7.8832e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01, -5.1021e-01,\n",
      "        -5.2133e-01, -6.7707e-01, -5.2133e-01, -6.6595e-01, -2.9884e-01,\n",
      "        -3.7671e-01, -7.7720e-01, -6.7707e-01, -8.1057e-01, -4.8796e-01,\n",
      "         2.7964e-01, -3.2109e-01, -8.1057e-01, -8.1057e-01, -7.9945e-01,\n",
      "        -8.1057e-01, -8.1057e-01, -8.1057e-01, -8.1057e-01])\n",
      "Tamanho da imagem tensor: 784\n",
      "------------------------------------------\n",
      "Tensor de imagens: tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]])\n",
      "Tamanho do Tensor: 100\n",
      "Imagem tensor: tensor([-0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.1320,  0.8470,  1.4032,  1.7036,  1.6035,  1.0139,\n",
      "         0.4243, -0.5770, -0.8106, -0.8106, -0.7994, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.7661, -0.8106, -0.7216,  1.9928,  1.9372,  1.9150,\n",
      "         1.8482,  1.8593,  1.8816,  1.8482,  1.9261,  1.8705,  0.3130, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.7216, -0.8106,\n",
      "         0.9805,  2.0262,  1.6591,  1.7815,  1.7370,  1.7481,  1.6925,  1.7703,\n",
      "         1.7926,  1.7258,  1.8593, -0.5992, -0.8106, -0.7661, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.7772, -0.8106, -0.8106,  1.7703,  1.8482,  1.7481,  1.7592,\n",
      "         1.9038,  2.0151,  2.0040,  1.9706,  1.7926,  1.6813,  1.9483,  0.3130,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.7883, -0.8106, -0.8106, -0.8106,\n",
      "         1.7592,  1.7926,  1.7703,  1.7815,  1.9483,  1.0250,  1.3699,  2.0040,\n",
      "         1.6591,  1.7481,  1.8593,  1.7036, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.7994,\n",
      "        -0.8106, -0.8106,  0.8136,  1.6813,  1.8260,  1.8260,  1.8482,  1.8037,\n",
      "         1.9928,  0.7914,  1.2252,  1.9483,  1.7815,  1.8593,  1.8037,  1.8705,\n",
      "         1.7036,  0.4131, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  1.1585,  2.0151,  1.7481,\n",
      "         1.7703,  1.7592,  1.8037,  1.7926,  1.8260,  1.9928,  1.9595,  1.8705,\n",
      "         1.8148,  1.7926,  1.7815,  1.7592,  1.7370,  1.9928,  0.3909, -0.8106,\n",
      "        -0.7438, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.5325,  1.8593,  1.6702,  1.7370,  1.8037,  1.7592,  1.7815,  1.7592,\n",
      "         1.7258,  1.7147,  1.7592,  1.7147,  1.7370,  1.7703,  1.7815,  1.7592,\n",
      "         1.7147,  1.7926,  1.4477, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106,  0.5133,  1.9261,  1.7147,  1.7481,\n",
      "         1.7370,  1.7926,  1.7481,  1.8148,  2.0151,  1.9706,  1.9817,  1.9706,\n",
      "         2.0040,  1.7481,  1.7592,  1.7592,  1.7258,  1.7370,  1.8260, -0.4991,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "         1.1251,  1.8705,  1.7258,  1.7147,  1.7815,  1.7036,  1.7592,  1.8148,\n",
      "         1.0917,  1.5701,  1.3587,  1.4477,  1.4477,  2.0262,  1.9150,  1.7592,\n",
      "         1.7481,  1.7147,  1.9261,  0.4354, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106,  1.7370,  1.8148,  1.7592,  1.7592,\n",
      "         1.8037,  1.9483,  1.9261,  1.9928,  0.8581,  0.6245,  0.1350,  0.8359,\n",
      "        -0.6882, -0.1431,  1.9817,  1.8260,  1.7592,  1.7703,  1.8927,  1.1585,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "         1.9261,  1.7815,  1.7815,  1.7926,  1.7370,  1.0584,  1.2252,  1.0917,\n",
      "         0.7691,  1.0695,  1.1919,  1.0139,  0.1906, -0.6103,  0.3464,  2.0262,\n",
      "         1.7258,  1.7815,  1.8260,  1.6480, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106,  2.0262,  1.7147,  1.7926,  1.7926,\n",
      "         1.7703,  1.1696,  1.2809,  0.7803,  0.9694,  1.1474,  0.9916,  0.8915,\n",
      "        -0.3211,  0.1573, -0.0541,  2.0151,  1.7703,  1.8037,  1.7703,  1.9372,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.7327,\n",
      "         2.0262,  1.6925,  1.7703,  1.8148,  1.7258,  1.9928,  1.3031,  0.6801,\n",
      "        -0.1653,  0.3241,  0.4020,  0.2129, -0.4768,  0.2463,  0.1906,  2.0151,\n",
      "         1.7815,  1.8148,  1.7481,  2.0262, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.4101,  2.0262,  1.6702,  1.7815,  1.8260,\n",
      "         1.6925,  1.7481,  1.5701,  1.8816,  1.9595,  1.7036,  1.7926,  1.7926,\n",
      "         1.8260,  1.8705,  1.8371,  1.7926,  1.7703,  1.8260,  1.7370,  2.0262,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.0207,\n",
      "         2.0262,  1.6813,  1.7592,  1.8482,  1.6925,  1.7703,  1.8371,  1.7926,\n",
      "         1.7926,  1.8816,  1.8037,  1.8037,  1.8037,  1.7926,  1.7926,  1.7036,\n",
      "         1.7926,  1.8148,  1.7258,  2.0262, -0.5436, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106,  0.1906,  2.0262,  1.6813,  1.7481,  1.8371,\n",
      "         1.7147,  1.7703,  1.7592,  1.7592,  1.7592,  1.7370,  1.7258,  1.7258,\n",
      "         1.7258,  1.6925,  1.7036,  1.6925,  1.7815,  1.8260,  1.7258,  2.0262,\n",
      "        -0.3322, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  0.3575,\n",
      "         2.0262,  1.6368,  1.7258,  1.8705,  1.7481,  1.7815,  1.7592,  1.7592,\n",
      "         1.7703,  1.7592,  1.7481,  1.7370,  1.7258,  1.7147,  1.7258,  1.6925,\n",
      "         1.7926,  1.8037,  1.7370,  2.0262, -0.0430, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106,  0.6245,  2.0040,  1.6591,  1.7147,  1.8705,\n",
      "         1.7703,  1.7815,  1.7592,  1.7592,  1.7592,  1.7592,  1.7592,  1.7592,\n",
      "         1.7481,  1.7592,  1.7592,  1.7147,  1.8260,  1.8371,  1.7370,  2.0262,\n",
      "         0.1573, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  0.8692,\n",
      "         2.0040,  1.6368,  1.7481,  1.9261,  1.7592,  1.7592,  1.7703,  1.7815,\n",
      "         1.7815,  1.7592,  1.7481,  1.7592,  1.7481,  1.7592,  1.7703,  1.6925,\n",
      "         1.8371,  1.8816,  1.7147,  2.0262,  0.3019, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106,  1.0361,  1.9595,  1.6925,  1.6925,  1.6368,\n",
      "         1.8927,  1.7370,  1.7926,  1.7815,  1.7815,  1.7703,  1.7703,  1.7703,\n",
      "         1.7703,  1.7370,  1.7036,  1.7592,  1.7926,  1.9150,  1.7370,  2.0262,\n",
      "         0.4910, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  1.1919,\n",
      "         1.8593,  1.8260,  1.5812,  0.7469,  2.0262,  1.7036,  1.7703,  1.7703,\n",
      "         1.7703,  1.7703,  1.7592,  1.7592,  1.7703,  1.7370,  1.7258,  1.9150,\n",
      "         1.2364,  1.8482,  1.7703,  2.0151,  0.7691, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106,  1.2475,  1.8371,  1.8705,  1.5812,  0.2574,\n",
      "         2.0262,  1.7147,  1.8037,  1.7926,  1.8037,  1.7926,  1.7926,  1.8037,\n",
      "         1.8037,  1.7815,  1.7258,  2.0262,  0.4576,  1.7703,  1.7815,  1.9706,\n",
      "         0.9026, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  1.3254,\n",
      "         1.7815,  1.7815,  1.6146,  0.1461,  1.9038,  1.6813,  1.7370,  1.7258,\n",
      "         1.7370,  1.7147,  1.7147,  1.7258,  1.7370,  1.7258,  1.7036,  1.7703,\n",
      "         0.4576,  1.8705,  1.7926,  1.7926,  1.1696, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106,  1.2475,  1.7815,  1.8037,  1.6813,  0.3686,\n",
      "         2.0262,  1.9038,  1.9261,  1.9261,  1.9261,  1.9261,  1.9261,  1.9261,\n",
      "         1.9261,  1.9372,  1.8927,  2.0151,  0.8359,  1.5701,  1.8037,  1.8037,\n",
      "         1.2475, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  0.2463,\n",
      "         1.8148,  1.7258,  1.3810, -0.8106,  0.3019,  0.6356,  0.7358,  0.7135,\n",
      "         0.7135,  0.7358,  0.7469,  0.7358,  0.7246,  0.5689,  0.3909,  0.0349,\n",
      "        -0.8106,  1.3365,  1.8148,  1.7926,  0.7246, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.1542,  1.8927,  1.9261,  1.7926, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,  1.2030,  1.9150,  1.9038,\n",
      "         0.6801, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.2098, -0.0318, -0.5325, -0.8106, -0.8106, -0.7994, -0.7994, -0.7994,\n",
      "        -0.7994, -0.7994, -0.7994, -0.7994, -0.7994, -0.7994, -0.7883, -0.7994,\n",
      "        -0.8106, -0.8106, -0.5102, -0.4768, -0.8106, -0.8106, -0.8106, -0.8106])\n",
      "Tamanho da imagem tensor: 784\n",
      "------------------------------------------\n",
      "Tensor de imagens: tensor([[-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        ...,\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106],\n",
      "        [-0.8106, -0.8106, -0.8106,  ..., -0.8106, -0.8106, -0.8106]])\n",
      "Tamanho do Tensor: 100\n",
      "Imagem tensor: tensor([-0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.7883, -0.8106, -0.8106,\n",
      "        -0.6215, -0.6771, -0.6882, -0.6771, -0.6993, -0.8106, -0.8106, -0.7994,\n",
      "        -0.8106, -0.7883, -0.7994, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7994, -0.7772, -0.8106,  0.6023,  0.7691,  0.6579,  0.6468,  0.5466,\n",
      "         0.8915, -0.4101, -0.8106, -0.7438, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.7883, -0.8106, -0.8106,  0.9360,\n",
      "        -0.2321, -0.2432, -0.1431, -0.4212,  0.3575,  0.7024, -0.8106, -0.7661,\n",
      "        -0.7994, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7994, -0.7994, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7549, -0.8106,  0.4020,  1.2475, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.3211,  1.3699, -0.8106, -0.8106, -0.7772, -0.7994, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.7994, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7994, -0.7549, -0.7216, -0.8106, -0.8106, -0.8106,  1.3810,  1.2920,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.1765,  1.7815, -0.1876, -0.8106,\n",
      "        -0.7994, -0.7549, -0.6993, -0.7549, -0.7994, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.7994, -0.7661, -0.7772, -0.7772, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106,  1.3810,  0.7914, -0.7549, -0.4880, -0.7772, -0.8106,\n",
      "        -0.3100,  1.7703,  0.9026, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7772, -0.7883, -0.8106, -0.8106, -0.7994, -0.7994, -0.7994, -0.8106,\n",
      "        -0.8106, -0.3545,  1.1474,  1.6368,  1.7481,  1.2586,  1.5478,  1.4032,\n",
      "         1.2920,  1.4366,  1.3031,  1.2364,  1.0027,  1.2364,  1.4589,  0.5021,\n",
      "         0.6023,  0.5578,  0.2908, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7883, -0.7994, -0.8106, -0.8106,  0.7024,  1.0472,  1.2030,  0.9360,\n",
      "         1.0695,  1.2475,  1.6035,  1.4032,  0.4131,  0.6023,  0.7691,  0.5355,\n",
      "         1.2586,  1.1696,  1.5145,  1.4477,  1.2697,  1.3476,  1.3921,  1.0917,\n",
      "         0.4688, -0.8106, -0.8106, -0.7994, -0.8106, -0.8106, -0.8106,  0.7358,\n",
      "         1.2697,  1.1140,  0.7469,  0.8470,  1.1140,  1.0695,  1.8482,  1.5478,\n",
      "         1.1585,  1.1807,  1.1251,  1.1585,  0.8136,  0.8136,  2.0151,  1.3476,\n",
      "         0.3798,  1.1029,  1.1696,  1.2809,  1.4477,  0.2796, -0.8106, -0.8106,\n",
      "        -0.7994, -0.8106,  0.1684,  1.4589,  1.2252,  1.2586,  1.4144,  1.6257,\n",
      "         0.5466,  0.7135,  1.8705,  1.2475,  0.8359,  1.2475,  1.0806,  1.1696,\n",
      "         1.2809,  1.1585,  1.6368,  1.5478,  1.2697,  1.4366,  1.5256,  1.5701,\n",
      "         1.3921,  1.1474, -0.8106, -0.8106, -0.8106, -0.8106,  1.0472,  1.5256,\n",
      "         1.2920,  1.3254,  1.3476,  1.5256,  1.2252,  0.2796, -0.6882,  0.6690,\n",
      "         1.4144,  1.2809,  1.3921,  1.4477,  0.7358,  1.8705,  0.1461,  0.3686,\n",
      "         1.8371,  1.6368,  1.6146,  1.5256,  1.5256,  1.3587, -0.5102, -0.8106,\n",
      "        -0.8106, -0.5658,  1.5145,  1.5034,  1.3810,  1.3254,  1.5478,  1.4811,\n",
      "         1.4255,  1.3476,  1.1029,  1.4144,  1.2809,  1.4144,  1.5812,  1.8148,\n",
      "         0.1461,  1.3810,  1.4589,  1.4032,  1.6702,  1.4811,  1.5923,  1.5590,\n",
      "         1.5145,  1.6257,  0.9137, -0.8106, -0.3656,  1.0027,  1.0584,  1.5812,\n",
      "         1.3365,  1.4700,  1.4366,  1.5034,  1.0806,  1.7147,  2.0262,  1.7036,\n",
      "         1.3587,  1.5812,  1.0695,  0.9916,  1.1029,  1.1474,  2.0262,  2.0151,\n",
      "         1.4477,  1.4922,  1.4589,  1.6480,  1.6257,  1.4366,  1.4477, -0.8106,\n",
      "         0.7135,  2.0262,  1.3699,  1.5256,  1.4255,  1.4144,  1.3921,  1.5367,\n",
      "         1.5034,  1.5145,  1.9150,  1.5145,  1.4477,  1.6368,  1.6813,  0.6913,\n",
      "         1.5256,  1.7592,  1.8593,  1.6813,  1.4589,  1.6591,  1.6368,  1.7036,\n",
      "         1.7036,  1.6257,  1.6813, -0.8106,  1.4477,  1.1029,  1.1919,  1.2475,\n",
      "         1.3921,  1.4255,  1.6813,  1.6146,  1.4922,  1.5478,  2.0040,  1.5256,\n",
      "         1.4144,  1.6702,  1.4811,  0.2685,  1.2697,  1.6591,  1.9372,  1.5812,\n",
      "         1.3365,  1.6925,  1.7036,  1.7370,  1.6257,  1.7036,  1.7036,  0.9360,\n",
      "         1.6925, -0.0207,  1.2586,  1.6813,  1.5034,  1.6035,  0.5133,  1.0027,\n",
      "         1.7370,  1.6146,  2.0040,  1.5812,  1.4589,  1.5923,  1.5590,  1.5478,\n",
      "         1.5034,  1.4255,  1.8927,  1.8593,  1.5590,  1.7703,  1.2252,  0.7246,\n",
      "         1.9150,  1.3921,  1.7258,  1.2697,  1.3587, -0.1987,  1.7592,  1.5145,\n",
      "         1.2920,  1.6257,  0.6356,  1.2920,  1.4255,  1.0472,  2.0262,  1.4811,\n",
      "         1.2809,  1.5590,  1.4811,  1.5701,  1.4477,  1.3365,  1.8482,  1.8816,\n",
      "         1.4032,  1.5923,  1.7703,  1.6925,  1.9483,  1.4032,  1.7815,  1.1140,\n",
      "         0.2796, -0.0207,  1.6480,  1.5590,  1.2697,  1.4032,  1.7147,  1.7815,\n",
      "         1.7481,  1.6480,  1.9817,  1.5923,  1.6480,  1.6257,  1.4255,  1.6591,\n",
      "         1.6480,  1.5478,  2.0151,  1.7481,  1.2030,  1.5367,  1.6257, -0.1542,\n",
      "         1.1696,  1.8037,  1.8816,  0.2463, -0.8106,  0.6356,  1.6146,  1.4032,\n",
      "         1.2586,  1.3476,  1.5590,  1.4144,  1.6257,  1.8482,  1.9038,  1.6702,\n",
      "         1.3365,  1.5145,  1.5256,  1.2030,  0.7135,  0.9026,  1.7481,  1.6591,\n",
      "         1.3031,  1.2920,  1.4366,  0.0127,  0.9805,  1.7481,  1.8371, -0.8106,\n",
      "        -0.8106,  1.1807,  2.0262,  1.7815,  1.7703,  1.7926,  1.8037,  1.7147,\n",
      "         1.7592,  1.7926,  1.8816,  1.7481,  1.8148,  1.8260,  1.7926,  1.6368,\n",
      "         1.4700,  1.6035,  1.9595,  1.9038,  1.5701,  1.7370,  1.7481,  1.5812,\n",
      "         1.3699,  1.7370, -0.1320, -0.8106, -0.8106,  0.4576,  1.6368,  1.5367,\n",
      "         1.6480,  1.6591,  2.0262,  2.0262,  1.7592,  1.7815,  1.7815,  1.4589,\n",
      "         0.9582,  1.1474,  1.0917,  1.2141,  1.2697,  1.1474,  1.2030,  0.8915,\n",
      "         0.6134,  1.0361,  0.9805,  0.6913,  1.0139,  0.8692, -0.1097, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.7772, -0.6993, -0.7216, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106,\n",
      "        -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106, -0.8106])\n",
      "Tamanho da imagem tensor: 784\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in treino_loader:\n",
    "    print(f\"Tensor de imagens: {i[0]}\\n\"\n",
    "          f\"Tamanho do Tensor: {len(i[0])}\\n\"\n",
    "          f\"Imagem tensor: {i[0][0]}\\n\"\n",
    "          f\"Tamanho da imagem tensor: {len(i[0][0])}\\n\"\n",
    "          f\"------------------------------------------\")"
   ]
  },
  {
   "source": [
    "Aqui pode-se notar que o primeiro tensor do par é um tensor em que cada elemento é um batch de 100 imagens-tensor. Vamos olhar o segundo elemento do par:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------------------\n",
      "Tensor de labels: tensor([1, 7, 8, 8, 8, 3, 7, 4, 6, 0, 9, 2, 0, 0, 7, 2, 6, 5, 3, 8, 8, 6, 5, 6,\n",
      "        1, 0, 6, 1, 4, 5, 4, 0, 3, 4, 6, 9, 2, 1, 5, 2, 2, 3, 3, 4, 3, 9, 0, 8,\n",
      "        5, 1, 6, 7, 5, 3, 9, 0, 6, 4, 7, 6, 1, 4, 3, 7, 7, 5, 8, 9, 7, 3, 6, 7,\n",
      "        9, 6, 0, 7, 1, 4, 7, 1, 3, 7, 8, 5, 8, 4, 5, 4, 5, 5, 8, 6, 3, 0, 4, 6,\n",
      "        1, 7, 2, 7])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 1\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 8, 3, 0, 3, 6, 6, 6, 6, 6, 3, 9, 6, 4, 1, 4, 8, 8, 9, 6, 5, 9, 9, 1,\n",
      "        8, 8, 5, 6, 6, 4, 5, 7, 8, 4, 4, 9, 5, 2, 6, 4, 3, 7, 8, 5, 3, 7, 3, 8,\n",
      "        9, 2, 9, 6, 3, 9, 1, 9, 2, 7, 3, 1, 4, 3, 3, 3, 7, 4, 4, 0, 1, 5, 3, 9,\n",
      "        9, 0, 8, 8, 4, 1, 3, 1, 3, 3, 4, 0, 4, 1, 5, 9, 4, 2, 7, 9, 9, 2, 7, 9,\n",
      "        6, 5, 6, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 8, 9, 7, 8, 7, 2, 4, 3, 2, 5, 2, 4, 9, 5, 5, 1, 7, 5, 4, 9, 9, 7, 3,\n",
      "        9, 9, 5, 3, 1, 4, 1, 8, 7, 8, 9, 0, 2, 5, 9, 9, 7, 4, 2, 2, 6, 3, 0, 6,\n",
      "        2, 5, 6, 5, 0, 5, 6, 5, 6, 6, 4, 4, 1, 1, 2, 4, 6, 6, 2, 2, 9, 2, 7, 1,\n",
      "        7, 3, 0, 0, 4, 4, 6, 6, 5, 4, 9, 4, 1, 8, 5, 0, 1, 0, 4, 6, 8, 7, 9, 8,\n",
      "        7, 6, 4, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 3, 8, 0, 9, 0, 1, 6, 5, 2, 5, 7, 8, 6, 9, 4, 4, 9, 4, 6, 9, 0, 2, 0,\n",
      "        6, 9, 3, 3, 3, 4, 8, 0, 9, 1, 6, 3, 7, 0, 5, 5, 2, 2, 1, 7, 0, 3, 6, 5,\n",
      "        8, 7, 4, 1, 9, 6, 3, 1, 5, 4, 2, 4, 0, 5, 6, 4, 4, 2, 4, 5, 8, 8, 5, 1,\n",
      "        7, 1, 9, 4, 2, 7, 9, 3, 7, 8, 5, 9, 3, 5, 6, 6, 1, 2, 1, 3, 9, 4, 6, 8,\n",
      "        6, 0, 3, 5])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([9, 8, 0, 2, 4, 2, 1, 1, 1, 7, 9, 2, 1, 1, 9, 2, 2, 2, 3, 6, 8, 1, 6, 3,\n",
      "        4, 7, 7, 8, 1, 3, 2, 8, 5, 0, 3, 2, 3, 5, 5, 3, 1, 3, 4, 4, 1, 3, 7, 0,\n",
      "        4, 2, 7, 4, 4, 4, 3, 5, 0, 4, 9, 9, 7, 2, 5, 6, 6, 9, 3, 4, 3, 4, 8, 1,\n",
      "        9, 8, 7, 5, 5, 9, 5, 4, 9, 0, 9, 8, 8, 9, 2, 4, 0, 8, 7, 5, 3, 3, 8, 0,\n",
      "        7, 6, 9, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 9\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([4, 8, 9, 9, 0, 5, 1, 9, 4, 9, 7, 6, 1, 0, 0, 2, 1, 9, 9, 6, 7, 6, 8, 5,\n",
      "        2, 9, 1, 2, 3, 4, 6, 2, 6, 1, 9, 2, 4, 7, 5, 8, 2, 9, 1, 2, 6, 0, 0, 5,\n",
      "        6, 9, 1, 2, 0, 6, 3, 0, 1, 4, 4, 1, 0, 1, 2, 0, 4, 6, 2, 5, 5, 4, 5, 9,\n",
      "        6, 2, 7, 2, 5, 3, 9, 9, 4, 2, 0, 7, 3, 2, 0, 0, 8, 0, 3, 8, 4, 0, 6, 1,\n",
      "        8, 2, 4, 7])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 4\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 2, 2, 5, 7, 8, 7, 8, 0, 8, 1, 6, 8, 8, 4, 2, 4, 4, 2, 3, 4, 6, 4, 0,\n",
      "        6, 0, 1, 4, 0, 9, 0, 8, 4, 9, 5, 4, 2, 8, 0, 0, 4, 4, 6, 6, 6, 6, 8, 3,\n",
      "        4, 3, 0, 2, 2, 7, 1, 0, 5, 2, 7, 7, 6, 7, 8, 8, 1, 3, 2, 0, 0, 5, 0, 5,\n",
      "        7, 3, 8, 7, 4, 8, 7, 7, 3, 2, 0, 7, 8, 3, 0, 8, 0, 3, 6, 7, 9, 1, 5, 9,\n",
      "        6, 6, 0, 9])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 3, 7, 8, 3, 7, 4, 9, 8, 1, 1, 1, 8, 2, 1, 5, 9, 0, 5, 2, 8, 9, 2, 1,\n",
      "        1, 3, 5, 9, 7, 2, 5, 2, 3, 9, 1, 5, 7, 6, 6, 9, 7, 6, 7, 2, 3, 9, 0, 2,\n",
      "        2, 7, 4, 4, 2, 5, 6, 4, 4, 6, 4, 8, 3, 4, 1, 5, 3, 1, 4, 8, 7, 3, 6, 6,\n",
      "        0, 9, 2, 1, 4, 3, 7, 1, 2, 7, 9, 7, 4, 1, 1, 1, 6, 9, 0, 8, 4, 1, 5, 4,\n",
      "        7, 0, 6, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([0, 0, 4, 5, 3, 2, 1, 3, 4, 2, 1, 6, 8, 6, 4, 8, 3, 5, 1, 3, 7, 3, 9, 1,\n",
      "        3, 0, 1, 6, 0, 0, 8, 1, 1, 9, 8, 6, 3, 9, 5, 8, 9, 4, 4, 9, 8, 8, 5, 5,\n",
      "        8, 0, 1, 3, 0, 5, 4, 8, 9, 3, 0, 7, 2, 0, 6, 4, 1, 3, 9, 4, 8, 7, 5, 0,\n",
      "        6, 4, 5, 6, 7, 1, 9, 5, 4, 0, 3, 0, 0, 9, 4, 7, 1, 6, 1, 6, 0, 3, 2, 0,\n",
      "        4, 8, 0, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 0\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([4, 1, 1, 3, 0, 5, 6, 3, 4, 2, 8, 5, 0, 7, 8, 2, 3, 0, 4, 0, 3, 5, 8, 9,\n",
      "        4, 4, 2, 0, 2, 6, 8, 6, 4, 9, 0, 1, 1, 9, 9, 5, 2, 4, 2, 3, 0, 3, 0, 5,\n",
      "        2, 7, 6, 3, 6, 6, 5, 2, 0, 9, 3, 3, 3, 4, 5, 7, 8, 2, 9, 5, 5, 3, 0, 5,\n",
      "        1, 0, 1, 5, 4, 7, 0, 3, 1, 6, 6, 0, 1, 6, 1, 6, 4, 7, 9, 7, 0, 8, 0, 5,\n",
      "        1, 3, 0, 0])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 4\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 4, 3, 8, 1, 9, 6, 8, 3, 3, 2, 6, 0, 3, 3, 6, 6, 7, 8, 2, 7, 1, 5, 7,\n",
      "        3, 0, 0, 8, 4, 4, 2, 1, 3, 3, 5, 3, 6, 4, 0, 4, 6, 3, 4, 9, 5, 3, 0, 1,\n",
      "        9, 5, 1, 8, 5, 8, 5, 2, 0, 3, 0, 9, 0, 7, 7, 3, 4, 5, 4, 0, 9, 9, 3, 9,\n",
      "        5, 1, 4, 8, 5, 9, 4, 8, 5, 5, 0, 2, 3, 3, 7, 5, 6, 0, 4, 9, 6, 7, 7, 0,\n",
      "        7, 8, 9, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([3, 6, 6, 7, 7, 8, 9, 4, 1, 9, 4, 7, 5, 3, 8, 6, 8, 7, 3, 2, 7, 1, 9, 8,\n",
      "        2, 9, 1, 1, 7, 3, 3, 6, 4, 6, 1, 1, 8, 8, 6, 8, 6, 1, 7, 1, 5, 0, 9, 5,\n",
      "        7, 7, 7, 6, 9, 1, 7, 2, 3, 9, 5, 0, 0, 5, 9, 8, 6, 8, 4, 9, 7, 2, 2, 8,\n",
      "        5, 1, 6, 0, 2, 1, 6, 8, 5, 6, 1, 6, 1, 1, 0, 3, 9, 4, 0, 8, 0, 1, 9, 0,\n",
      "        0, 9, 4, 5])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 3\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 5, 5, 1, 6, 8, 7, 1, 1, 2, 7, 4, 0, 6, 6, 1, 1, 2, 5, 2, 6, 5, 4, 0,\n",
      "        9, 7, 0, 1, 8, 8, 0, 5, 6, 2, 9, 1, 3, 5, 1, 8, 5, 0, 9, 9, 8, 6, 4, 7,\n",
      "        8, 9, 2, 8, 6, 5, 9, 2, 1, 8, 3, 6, 4, 2, 4, 1, 1, 3, 8, 4, 2, 6, 7, 8,\n",
      "        5, 6, 2, 6, 2, 0, 0, 0, 9, 4, 9, 6, 1, 5, 4, 5, 5, 6, 0, 4, 2, 5, 3, 3,\n",
      "        6, 9, 3, 4])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 7, 7, 7, 4, 6, 0, 3, 3, 3, 8, 7, 5, 3, 2, 4, 0, 2, 7, 3, 1, 3, 3, 4,\n",
      "        4, 0, 5, 3, 1, 4, 8, 3, 4, 5, 7, 2, 7, 1, 8, 0, 2, 6, 7, 1, 5, 4, 8, 5,\n",
      "        0, 8, 1, 5, 6, 9, 0, 8, 8, 6, 2, 4, 5, 2, 8, 7, 0, 8, 9, 3, 3, 3, 5, 2,\n",
      "        3, 2, 5, 1, 2, 0, 3, 0, 7, 1, 3, 5, 3, 3, 2, 0, 9, 3, 8, 5, 5, 6, 6, 6,\n",
      "        9, 7, 4, 3])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 8, 2, 0, 9, 4, 9, 8, 7, 3, 3, 6, 3, 3, 1, 1, 1, 2, 9, 1, 6, 0, 0, 6,\n",
      "        4, 5, 0, 4, 2, 5, 2, 8, 8, 6, 2, 5, 6, 4, 4, 7, 3, 0, 8, 1, 2, 2, 3, 9,\n",
      "        5, 2, 4, 3, 2, 8, 1, 9, 1, 1, 8, 0, 0, 8, 8, 6, 4, 5, 5, 6, 4, 2, 0, 6,\n",
      "        1, 5, 8, 6, 0, 1, 6, 9, 7, 2, 1, 3, 6, 8, 1, 5, 9, 5, 7, 9, 5, 9, 0, 0,\n",
      "        1, 3, 2, 4])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 0, 9, 9, 9, 1, 1, 5, 6, 3, 8, 5, 8, 4, 0, 1, 7, 1, 6, 4, 5, 9, 3, 6,\n",
      "        5, 4, 4, 4, 8, 7, 9, 0, 3, 6, 3, 4, 7, 7, 2, 2, 5, 8, 8, 5, 6, 0, 6, 7,\n",
      "        1, 7, 2, 0, 4, 8, 9, 5, 7, 5, 4, 4, 0, 5, 0, 0, 0, 0, 0, 7, 5, 1, 2, 8,\n",
      "        7, 2, 8, 1, 9, 7, 9, 8, 3, 0, 8, 4, 3, 6, 3, 7, 2, 1, 4, 7, 7, 6, 7, 3,\n",
      "        7, 1, 8, 0])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 2, 6, 2, 3, 5, 1, 3, 2, 1, 6, 6, 1, 5, 9, 2, 6, 2, 6, 6, 2, 9, 0, 3,\n",
      "        6, 5, 8, 5, 9, 5, 8, 5, 4, 8, 6, 5, 1, 4, 2, 0, 0, 0, 8, 0, 1, 2, 9, 2,\n",
      "        4, 8, 1, 9, 2, 8, 2, 6, 0, 9, 7, 1, 5, 9, 4, 3, 1, 2, 8, 5, 9, 0, 3, 1,\n",
      "        8, 1, 3, 4, 5, 5, 3, 2, 1, 9, 6, 5, 7, 0, 5, 7, 4, 4, 5, 9, 5, 1, 3, 4,\n",
      "        8, 5, 5, 0])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 3, 6, 8, 1, 0, 7, 8, 6, 8, 6, 9, 5, 8, 8, 7, 1, 2, 5, 6, 8, 5, 1, 6,\n",
      "        6, 0, 9, 9, 5, 9, 7, 4, 2, 0, 3, 7, 9, 3, 0, 7, 1, 5, 8, 2, 6, 4, 5, 9,\n",
      "        4, 1, 9, 7, 9, 2, 0, 1, 3, 2, 5, 9, 7, 7, 0, 7, 4, 2, 7, 6, 9, 0, 8, 1,\n",
      "        1, 0, 2, 2, 1, 6, 6, 2, 7, 5, 3, 7, 8, 0, 6, 4, 4, 1, 3, 9, 4, 2, 4, 1,\n",
      "        4, 1, 0, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([3, 0, 1, 3, 6, 1, 2, 7, 3, 6, 3, 0, 1, 3, 0, 7, 4, 5, 6, 5, 0, 4, 3, 0,\n",
      "        3, 0, 8, 3, 4, 3, 1, 1, 5, 7, 0, 8, 1, 5, 9, 3, 4, 0, 7, 0, 4, 3, 8, 2,\n",
      "        2, 3, 0, 3, 7, 1, 0, 3, 5, 6, 0, 5, 4, 9, 1, 2, 6, 1, 7, 6, 9, 8, 4, 2,\n",
      "        2, 6, 8, 5, 2, 5, 8, 9, 7, 8, 3, 9, 4, 7, 8, 8, 8, 7, 0, 1, 6, 9, 6, 4,\n",
      "        3, 5, 5, 1])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 3\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([9, 2, 4, 1, 4, 2, 4, 7, 4, 5, 4, 8, 3, 1, 0, 5, 9, 3, 2, 0, 7, 9, 3, 1,\n",
      "        7, 9, 6, 5, 6, 4, 5, 9, 4, 8, 5, 8, 6, 5, 4, 5, 6, 4, 6, 3, 3, 5, 2, 3,\n",
      "        5, 9, 8, 6, 9, 2, 5, 8, 7, 2, 6, 0, 2, 2, 5, 3, 8, 6, 2, 9, 4, 2, 2, 9,\n",
      "        1, 1, 6, 5, 4, 0, 9, 1, 1, 3, 1, 1, 0, 7, 7, 8, 7, 8, 2, 1, 7, 3, 3, 6,\n",
      "        7, 2, 4, 8])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 9\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 6, 3, 4, 4, 9, 7, 9, 6, 5, 7, 4, 4, 7, 9, 1, 6, 9, 4, 7, 5, 4, 0, 9,\n",
      "        0, 1, 5, 8, 7, 6, 5, 4, 1, 2, 9, 5, 0, 6, 3, 2, 5, 7, 3, 5, 1, 9, 1, 0,\n",
      "        6, 4, 8, 8, 5, 0, 8, 2, 4, 3, 7, 2, 1, 4, 2, 8, 1, 9, 0, 9, 7, 3, 5, 9,\n",
      "        4, 9, 3, 2, 9, 4, 4, 6, 3, 9, 8, 6, 4, 8, 1, 5, 8, 2, 1, 6, 0, 9, 1, 3,\n",
      "        2, 9, 8, 4])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([3, 6, 1, 8, 1, 9, 3, 3, 5, 3, 7, 7, 0, 1, 2, 2, 9, 1, 0, 5, 2, 2, 6, 3,\n",
      "        0, 5, 2, 8, 6, 5, 3, 0, 7, 2, 2, 0, 4, 6, 5, 1, 3, 4, 7, 0, 3, 4, 7, 3,\n",
      "        5, 2, 8, 8, 7, 0, 1, 1, 1, 3, 7, 9, 5, 7, 0, 2, 4, 6, 2, 4, 0, 2, 8, 0,\n",
      "        7, 4, 1, 3, 2, 7, 9, 9, 0, 7, 6, 0, 3, 8, 2, 5, 0, 5, 9, 3, 8, 8, 7, 1,\n",
      "        6, 1, 2, 3])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 3\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([0, 5, 0, 6, 0, 5, 3, 6, 6, 3, 1, 4, 4, 0, 9, 0, 7, 5, 7, 8, 9, 4, 6, 9,\n",
      "        9, 6, 6, 0, 8, 7, 7, 8, 4, 2, 8, 2, 3, 5, 3, 7, 3, 6, 3, 1, 2, 4, 0, 1,\n",
      "        7, 6, 2, 7, 7, 4, 9, 0, 6, 6, 1, 7, 4, 8, 4, 0, 4, 8, 5, 7, 0, 6, 1, 2,\n",
      "        3, 1, 2, 2, 6, 2, 8, 3, 9, 7, 8, 9, 3, 7, 0, 2, 5, 8, 0, 5, 6, 9, 1, 3,\n",
      "        2, 3, 8, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 0\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([4, 9, 0, 8, 1, 0, 5, 7, 0, 7, 3, 9, 7, 5, 7, 7, 3, 1, 0, 4, 8, 4, 5, 9,\n",
      "        5, 8, 2, 8, 6, 5, 6, 7, 8, 8, 2, 7, 4, 9, 4, 9, 2, 0, 1, 7, 9, 1, 1, 0,\n",
      "        1, 7, 9, 4, 6, 0, 3, 4, 4, 2, 8, 7, 9, 3, 5, 2, 6, 5, 5, 1, 5, 5, 6, 9,\n",
      "        7, 6, 5, 1, 6, 3, 6, 9, 6, 3, 6, 1, 2, 2, 5, 4, 4, 3, 8, 0, 5, 2, 0, 1,\n",
      "        3, 3, 8, 6])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 4\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 9, 7, 8, 5, 8, 8, 0, 4, 8, 2, 1, 5, 8, 4, 4, 6, 8, 6, 9, 3, 7, 2, 3,\n",
      "        3, 0, 3, 0, 7, 5, 1, 0, 3, 4, 7, 9, 7, 1, 6, 6, 9, 2, 0, 6, 5, 4, 3, 6,\n",
      "        5, 1, 4, 9, 9, 1, 3, 0, 4, 4, 2, 8, 8, 6, 4, 6, 1, 9, 9, 8, 4, 8, 5, 8,\n",
      "        4, 2, 5, 5, 4, 7, 3, 9, 4, 9, 4, 0, 9, 8, 4, 3, 2, 5, 7, 9, 0, 1, 2, 4,\n",
      "        5, 5, 9, 9])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([3, 7, 3, 1, 6, 1, 7, 1, 0, 5, 9, 7, 0, 4, 1, 1, 7, 7, 8, 6, 7, 0, 1, 1,\n",
      "        9, 9, 4, 1, 2, 4, 0, 0, 4, 7, 6, 3, 0, 9, 1, 9, 1, 4, 6, 4, 8, 7, 1, 4,\n",
      "        9, 4, 0, 9, 9, 9, 0, 7, 3, 7, 9, 4, 4, 9, 0, 9, 3, 1, 4, 9, 0, 5, 5, 6,\n",
      "        7, 3, 0, 3, 0, 5, 2, 2, 0, 2, 9, 8, 8, 8, 9, 8, 2, 3, 4, 5, 8, 0, 2, 6,\n",
      "        1, 6, 1, 7])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 3\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 7, 1, 0, 4, 6, 0, 6, 1, 5, 9, 0, 2, 8, 2, 3, 8, 2, 7, 8, 5, 7, 5, 5,\n",
      "        2, 8, 2, 4, 5, 9, 6, 2, 8, 2, 1, 8, 7, 0, 3, 5, 7, 8, 1, 8, 6, 2, 4, 0,\n",
      "        3, 6, 8, 3, 2, 4, 8, 6, 3, 3, 0, 6, 5, 9, 8, 0, 4, 6, 9, 8, 2, 0, 3, 9,\n",
      "        1, 6, 9, 8, 9, 3, 4, 3, 0, 3, 1, 3, 2, 3, 9, 3, 7, 7, 8, 2, 1, 1, 3, 7,\n",
      "        1, 9, 9, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 2, 4, 4, 9, 1, 6, 7, 0, 9, 7, 4, 6, 0, 9, 1, 1, 2, 5, 2, 4, 0, 9, 8,\n",
      "        5, 3, 7, 2, 8, 2, 0, 5, 9, 8, 8, 8, 6, 2, 3, 1, 9, 3, 4, 4, 0, 4, 7, 1,\n",
      "        1, 5, 2, 2, 2, 0, 7, 8, 4, 6, 0, 0, 7, 4, 7, 7, 7, 1, 8, 3, 7, 0, 5, 2,\n",
      "        7, 7, 6, 6, 0, 0, 9, 6, 1, 7, 5, 6, 5, 7, 4, 9, 4, 6, 2, 9, 0, 4, 5, 8,\n",
      "        1, 7, 8, 1])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 4, 5, 9, 7, 7, 6, 9, 5, 7, 0, 2, 2, 6, 5, 0, 1, 1, 5, 5, 3, 5, 8, 7,\n",
      "        4, 2, 5, 9, 3, 2, 1, 2, 2, 6, 9, 1, 3, 4, 0, 6, 9, 3, 8, 6, 7, 3, 9, 1,\n",
      "        1, 4, 2, 3, 7, 5, 9, 8, 1, 1, 1, 5, 9, 5, 3, 7, 4, 7, 5, 3, 0, 0, 1, 4,\n",
      "        1, 1, 6, 6, 4, 8, 7, 2, 6, 2, 1, 7, 3, 2, 4, 7, 2, 5, 9, 1, 4, 0, 7, 6,\n",
      "        6, 6, 7, 4])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([7, 0, 7, 4, 4, 6, 8, 1, 3, 5, 5, 8, 7, 7, 4, 4, 3, 6, 8, 0, 2, 0, 6, 6,\n",
      "        9, 6, 8, 3, 1, 4, 7, 1, 1, 2, 3, 7, 2, 0, 6, 3, 7, 1, 9, 0, 4, 0, 6, 7,\n",
      "        8, 5, 2, 1, 3, 5, 8, 2, 8, 6, 9, 0, 7, 6, 2, 4, 4, 2, 3, 1, 2, 7, 9, 4,\n",
      "        5, 3, 2, 1, 5, 3, 4, 9, 6, 1, 7, 7, 9, 8, 6, 7, 3, 1, 2, 4, 9, 4, 0, 1,\n",
      "        2, 6, 4, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 7\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 1, 7, 1, 4, 9, 0, 8, 1, 9, 4, 9, 7, 5, 2, 6, 5, 1, 0, 8, 6, 1, 8, 8,\n",
      "        4, 1, 2, 1, 1, 3, 0, 8, 3, 3, 9, 2, 9, 1, 2, 7, 4, 0, 9, 5, 2, 5, 5, 7,\n",
      "        9, 3, 1, 2, 9, 6, 4, 0, 2, 2, 6, 8, 3, 4, 0, 0, 4, 2, 7, 5, 9, 4, 6, 5,\n",
      "        0, 3, 0, 4, 0, 9, 3, 0, 6, 7, 0, 6, 3, 3, 8, 6, 4, 1, 7, 5, 5, 6, 5, 7,\n",
      "        1, 9, 0, 8])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([0, 6, 2, 3, 9, 2, 4, 8, 0, 4, 1, 3, 5, 3, 4, 1, 2, 4, 4, 4, 8, 1, 3, 3,\n",
      "        5, 3, 6, 5, 1, 6, 4, 2, 5, 6, 0, 8, 5, 6, 5, 6, 1, 4, 8, 5, 3, 7, 4, 6,\n",
      "        2, 5, 1, 1, 2, 9, 5, 1, 1, 3, 8, 9, 8, 7, 4, 5, 1, 7, 3, 4, 5, 2, 9, 6,\n",
      "        5, 7, 9, 9, 1, 6, 9, 5, 3, 4, 9, 5, 0, 7, 2, 0, 4, 5, 0, 9, 7, 5, 6, 4,\n",
      "        8, 7, 4, 7])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 0\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 8, 2, 2, 9, 8, 5, 5, 1, 3, 5, 0, 2, 7, 9, 1, 2, 5, 2, 3, 9, 1, 5, 8,\n",
      "        3, 2, 8, 3, 3, 8, 0, 2, 7, 8, 7, 9, 1, 6, 2, 5, 8, 8, 4, 1, 9, 8, 4, 1,\n",
      "        6, 5, 1, 7, 2, 5, 3, 6, 7, 9, 6, 6, 8, 0, 5, 2, 5, 3, 2, 6, 1, 5, 9, 7,\n",
      "        5, 9, 4, 2, 3, 7, 2, 1, 6, 4, 4, 1, 2, 2, 3, 9, 8, 4, 8, 9, 1, 6, 3, 6,\n",
      "        1, 5, 4, 3])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 5, 8, 2, 9, 0, 8, 9, 0, 9, 7, 4, 1, 8, 9, 9, 9, 7, 9, 1, 1, 5, 3, 6,\n",
      "        7, 0, 1, 7, 4, 1, 0, 8, 4, 8, 0, 7, 8, 7, 2, 0, 6, 9, 6, 0, 9, 2, 8, 9,\n",
      "        0, 5, 2, 7, 0, 6, 2, 0, 4, 4, 5, 3, 4, 3, 8, 4, 2, 0, 2, 1, 1, 5, 5, 4,\n",
      "        6, 5, 7, 0, 8, 3, 5, 1, 4, 9, 4, 9, 8, 7, 1, 7, 6, 1, 1, 4, 5, 8, 6, 3,\n",
      "        5, 7, 3, 4])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([5, 4, 3, 4, 4, 2, 5, 4, 3, 8, 5, 4, 5, 8, 6, 5, 7, 5, 5, 5, 3, 5, 7, 7,\n",
      "        7, 2, 0, 4, 0, 5, 3, 0, 4, 6, 5, 0, 6, 3, 0, 3, 3, 4, 4, 4, 6, 9, 8, 6,\n",
      "        1, 9, 1, 1, 9, 5, 3, 0, 6, 5, 0, 6, 0, 0, 2, 2, 2, 6, 2, 7, 4, 8, 2, 1,\n",
      "        3, 7, 7, 8, 5, 6, 4, 2, 4, 7, 8, 7, 7, 1, 9, 0, 8, 0, 2, 1, 2, 3, 0, 4,\n",
      "        6, 8, 0, 9])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 5\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 3, 1, 5, 7, 2, 6, 2, 5, 3, 3, 2, 4, 8, 7, 7, 1, 2, 6, 5, 5, 3, 4, 6,\n",
      "        9, 8, 2, 0, 8, 5, 9, 6, 9, 9, 7, 9, 6, 7, 7, 0, 3, 4, 9, 9, 6, 8, 5, 5,\n",
      "        0, 5, 0, 6, 9, 0, 8, 2, 6, 9, 3, 2, 4, 8, 7, 2, 2, 5, 9, 5, 4, 0, 8, 1,\n",
      "        1, 6, 9, 4, 5, 7, 4, 6, 4, 6, 4, 4, 0, 9, 6, 3, 1, 3, 2, 4, 0, 1, 1, 6,\n",
      "        2, 4, 9, 0])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([4, 1, 8, 6, 5, 7, 9, 2, 5, 1, 9, 1, 4, 1, 3, 7, 1, 1, 1, 6, 7, 9, 1, 0,\n",
      "        2, 5, 4, 2, 6, 9, 3, 4, 8, 5, 7, 2, 7, 4, 8, 4, 5, 3, 8, 9, 7, 8, 7, 4,\n",
      "        4, 0, 6, 4, 0, 7, 3, 0, 8, 1, 4, 4, 8, 8, 3, 3, 3, 3, 4, 5, 8, 3, 2, 8,\n",
      "        7, 9, 3, 3, 8, 6, 1, 5, 2, 1, 1, 7, 0, 8, 6, 5, 8, 7, 4, 1, 1, 4, 6, 5,\n",
      "        0, 0, 1, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 4\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([6, 7, 1, 0, 8, 5, 8, 9, 2, 7, 0, 1, 0, 8, 3, 4, 2, 4, 5, 2, 2, 3, 1, 8,\n",
      "        1, 7, 4, 9, 0, 9, 2, 4, 8, 5, 7, 7, 3, 6, 3, 0, 2, 1, 8, 2, 4, 5, 7, 2,\n",
      "        5, 0, 1, 0, 5, 5, 2, 7, 2, 3, 7, 4, 8, 8, 0, 7, 9, 7, 3, 2, 5, 1, 0, 2,\n",
      "        2, 2, 4, 4, 3, 1, 9, 3, 8, 1, 4, 2, 4, 4, 1, 9, 6, 2, 4, 2, 7, 0, 7, 5,\n",
      "        2, 2, 9, 7])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 6\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([9, 7, 6, 8, 2, 0, 3, 0, 9, 2, 3, 3, 6, 0, 4, 5, 5, 9, 0, 3, 0, 2, 8, 9,\n",
      "        4, 9, 5, 0, 8, 9, 2, 1, 8, 3, 0, 6, 2, 8, 5, 3, 5, 2, 5, 1, 9, 8, 3, 7,\n",
      "        9, 8, 0, 5, 1, 7, 3, 5, 0, 8, 3, 9, 9, 1, 5, 5, 2, 7, 0, 3, 4, 7, 6, 4,\n",
      "        9, 5, 9, 6, 4, 8, 3, 2, 8, 7, 6, 5, 8, 2, 4, 5, 5, 1, 2, 0, 0, 0, 9, 3,\n",
      "        9, 6, 8, 8])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 9\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([1, 0, 1, 5, 9, 0, 9, 4, 1, 6, 3, 2, 1, 8, 7, 2, 5, 4, 1, 2, 6, 0, 7, 9,\n",
      "        0, 5, 2, 0, 9, 3, 5, 5, 4, 2, 1, 8, 9, 5, 3, 4, 4, 1, 9, 0, 4, 6, 1, 1,\n",
      "        9, 0, 9, 9, 3, 4, 9, 6, 2, 7, 9, 8, 4, 2, 6, 2, 7, 1, 4, 9, 3, 1, 5, 1,\n",
      "        5, 2, 6, 7, 0, 5, 9, 4, 1, 1, 4, 9, 9, 8, 5, 8, 0, 0, 9, 9, 3, 0, 1, 8,\n",
      "        5, 8, 8, 8])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 1\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 1, 1, 9, 6, 2, 8, 1, 5, 5, 9, 6, 9, 2, 7, 4, 2, 3, 3, 0, 4, 9, 8, 8,\n",
      "        9, 6, 2, 4, 2, 9, 3, 7, 2, 2, 1, 6, 1, 0, 8, 6, 5, 1, 4, 0, 6, 3, 9, 8,\n",
      "        9, 9, 0, 3, 0, 1, 0, 0, 4, 3, 3, 8, 1, 1, 8, 3, 2, 7, 2, 2, 3, 3, 7, 6,\n",
      "        2, 2, 8, 5, 8, 4, 8, 9, 0, 7, 7, 8, 7, 1, 9, 4, 7, 1, 6, 2, 5, 3, 3, 4,\n",
      "        3, 3, 2, 1])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([4, 2, 4, 6, 3, 6, 2, 5, 0, 0, 9, 0, 6, 0, 4, 3, 8, 0, 9, 5, 0, 8, 0, 6,\n",
      "        0, 1, 3, 2, 0, 3, 7, 8, 8, 1, 0, 1, 8, 9, 6, 3, 3, 2, 4, 9, 0, 6, 9, 9,\n",
      "        8, 3, 5, 4, 9, 4, 5, 7, 6, 1, 0, 7, 1, 2, 8, 4, 1, 7, 9, 9, 7, 4, 6, 6,\n",
      "        9, 4, 4, 4, 8, 2, 0, 7, 5, 2, 5, 8, 7, 7, 5, 0, 6, 3, 4, 8, 5, 3, 8, 1,\n",
      "        3, 4, 4, 3])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 4\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 2, 1, 3, 7, 1, 1, 9, 4, 6, 7, 2, 2, 9, 7, 8, 8, 0, 6, 7, 5, 4, 5, 7,\n",
      "        1, 4, 7, 6, 0, 3, 0, 2, 0, 1, 4, 3, 8, 9, 8, 4, 0, 3, 0, 4, 6, 6, 9, 6,\n",
      "        9, 6, 4, 1, 3, 6, 8, 9, 7, 3, 2, 5, 1, 8, 0, 5, 1, 5, 9, 2, 2, 6, 7, 4,\n",
      "        6, 1, 0, 8, 8, 3, 4, 1, 0, 5, 1, 9, 3, 2, 8, 0, 4, 3, 3, 6, 4, 1, 8, 8,\n",
      "        9, 1, 4, 1])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([6, 0, 6, 2, 1, 2, 2, 1, 5, 2, 6, 4, 4, 0, 3, 8, 6, 8, 7, 9, 3, 4, 3, 3,\n",
      "        8, 8, 3, 7, 0, 0, 6, 9, 5, 5, 1, 2, 9, 0, 6, 6, 1, 2, 1, 5, 4, 3, 4, 1,\n",
      "        6, 8, 9, 8, 4, 3, 0, 5, 3, 0, 1, 2, 5, 2, 4, 3, 7, 1, 0, 7, 0, 1, 0, 2,\n",
      "        8, 1, 2, 6, 5, 6, 4, 1, 9, 4, 3, 4, 4, 1, 7, 8, 9, 0, 6, 9, 5, 7, 2, 7,\n",
      "        2, 4, 5, 2])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 6\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([2, 6, 8, 2, 9, 0, 8, 2, 6, 8, 0, 4, 8, 1, 9, 7, 5, 1, 8, 5, 2, 5, 3, 8,\n",
      "        9, 9, 5, 2, 6, 1, 7, 9, 7, 5, 6, 7, 9, 8, 5, 1, 9, 5, 6, 3, 7, 9, 0, 6,\n",
      "        2, 9, 0, 9, 6, 1, 7, 7, 1, 5, 2, 9, 2, 9, 4, 2, 0, 0, 3, 8, 0, 7, 0, 3,\n",
      "        4, 6, 1, 8, 4, 4, 6, 1, 0, 1, 2, 8, 8, 1, 1, 1, 2, 5, 9, 5, 8, 2, 1, 4,\n",
      "        5, 7, 0, 0])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 2\n",
      "------------------------------------------\n",
      "Tensor de labels: tensor([8, 8, 7, 4, 2, 7, 2, 4, 1, 3, 0, 8, 4, 1, 6, 2, 8, 1, 2, 0, 9, 3, 8, 2,\n",
      "        7, 8, 2, 6, 2, 6, 2, 6, 4, 3, 7, 2, 9, 2, 4, 0, 0, 9, 3, 8, 0, 0, 7, 0,\n",
      "        3, 9, 2, 3, 2, 1, 9, 1, 3, 1, 6, 3, 2, 3, 2, 2, 0, 4, 9, 1, 1, 6, 8, 6,\n",
      "        1, 0, 0, 1, 5, 4, 1, 9, 4, 2, 2, 4, 2, 2, 6, 0, 7, 5, 6, 0, 6, 4, 9, 2,\n",
      "        9, 4, 4, 9])\n",
      "Tamanho do Tensor: 100\n",
      "Label: 8\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in treino_loader:\n",
    "    print(f\"Tensor de labels: {i[1]}\\n\"\n",
    "          f\"Tamanho do Tensor: {len(i[1])}\\n\"\n",
    "          f\"Label: {i[1][0]}\\n\"\n",
    "          f\"------------------------------------------\")"
   ]
  },
  {
   "source": [
    "Aqui pode-se notar que o segundo tensor do par é um tensor em que cada elemento é um batch de 100 classificações."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteração: 500 | Loss: 0.9487448334693909 | Acurácia: 73.19400024414062\n",
      "Iteração: 1000 | Loss: 0.8579804301261902 | Acurácia: 76.09400177001953\n",
      "Iteração: 1500 | Loss: 0.8200242519378662 | Acurácia: 77.63999938964844\n",
      "Iteração: 2000 | Loss: 0.7977936267852783 | Acurácia: 78.69999694824219\n",
      "Iteração: 2500 | Loss: 0.782673716545105 | Acurácia: 79.43399810791016\n",
      "Iteração: 3000 | Loss: 0.7714732885360718 | Acurácia: 79.98200225830078\n",
      "Iteração: 3500 | Loss: 0.7626940011978149 | Acurácia: 80.41000366210938\n",
      "Iteração: 4000 | Loss: 0.7555271983146667 | Acurácia: 80.83200073242188\n",
      "Iteração: 4500 | Loss: 0.7494957447052002 | Acurácia: 81.16600036621094\n",
      "Iteração: 5000 | Loss: 0.7443002462387085 | Acurácia: 81.50399780273438\n",
      "Iteração: 5500 | Loss: 0.7397421002388 | Acurácia: 81.75599670410156\n",
      "Iteração: 6000 | Loss: 0.7356856465339661 | Acurácia: 81.99600219726562\n",
      "Iteração: 6500 | Loss: 0.732033908367157 | Acurácia: 82.22000122070312\n",
      "Iteração: 7000 | Loss: 0.7287164330482483 | Acurácia: 82.36199951171875\n",
      "Iteração: 7500 | Loss: 0.725680410861969 | Acurácia: 82.50399780273438\n",
      "Iteração: 8000 | Loss: 0.7228849530220032 | Acurácia: 82.66999816894531\n",
      "Iteração: 8500 | Loss: 0.7202979326248169 | Acurácia: 82.81400299072266\n",
      "Iteração: 9000 | Loss: 0.7178935408592224 | Acurácia: 82.947998046875\n",
      "Iteração: 9500 | Loss: 0.7156504988670349 | Acurácia: 83.0719985961914\n",
      "Iteração: 10000 | Loss: 0.7135514616966248 | Acurácia: 83.16600036621094\n"
     ]
    }
   ],
   "source": [
    "contagem = 0\n",
    "lista_loss = []\n",
    "lista_iteracao = []\n",
    "for epoch in range(n_epochs):\n",
    "    for imagens, classificacao in treino_loader:\n",
    "        \n",
    "        # Utilizando a função Variable() crie as seguintes variáveis:\n",
    "        treino = Variable(imagens.view(-1, 28*28)) # Crie uma variável com as imagens, porém, mude a forma do tensor\n",
    "                                                   # para ([100,28*28]) com o método .view()\n",
    "        \n",
    "        validacao = Variable(classificacao)     # Cire uma variável com a classificacao\n",
    "\n",
    "        # Limpamos os gradientes\n",
    "        optmizador.zero_grad()\n",
    "\n",
    "        # Utilize o método .forward() do modelo utilizando a variável de treino\n",
    "        # para realizarmos a forward propagation\n",
    "        outputs = modelo(treino) \n",
    "\n",
    "        # Utilize a função de perda erro() com nosso output e a variável de verificação\n",
    "        loss = erro(outputs, validacao)\n",
    "\n",
    "        # Realizamos a backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualiza os parâmetros\n",
    "        optmizador.step() \n",
    "\n",
    "        contagem += 1\n",
    "\n",
    "        # Predições\n",
    "        if contagem % 50 == 0:\n",
    "            # Calculamos a acurácia\n",
    "            corretos = 0\n",
    "            total = 0\n",
    "\n",
    "            for imagens, classificacao in treino_loader:\n",
    "                \n",
    "                # Crie uma variável com as imagens da mesma maneira como na variável de treino\n",
    "                teste = Variable(imagens.view(-1, 28*28))\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = modelo(teste)\n",
    "                \n",
    "                # Recebe as predições do valor máximo\n",
    "                predito =  torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                # Número total de classificações\n",
    "                total += len(classificacao)\n",
    "\n",
    "                # Número de predições corretas\n",
    "                corretos += (predito == classificacao).sum()\n",
    "\n",
    "            acuracia = 100 * corretos / float(total)\n",
    "\n",
    "            # Armazena a loss e iteração\n",
    "            lista_loss.append(loss.data)\n",
    "            lista_iteracao.append(contagem)\n",
    "\n",
    "        if contagem % 500 == 0:\n",
    "            # Printa a loss\n",
    "            print(f\"Iteração: {contagem} | Loss: {loss.data} | Acurácia: {acuracia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 1800x432 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"386.762812pt\" version=\"1.1\" viewBox=\"0 0 1445.98125 386.762812\" width=\"1445.98125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-01-20T19:50:18.553240</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 386.762812 \nL 1445.98125 386.762812 \nL 1445.98125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 348.958125 \nL 1438.78125 348.958125 \nL 1438.78125 22.798125 \nL 43.78125 22.798125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m472e11d218\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"100.817568\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(97.636318 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"355.728486\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(343.003486 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"610.639404\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(597.914404 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"865.550323\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(852.825323 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1120.461241\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(1107.736241 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1375.372159\" xlink:href=\"#m472e11d218\" y=\"348.958125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(1359.465909 363.556562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Número de Iterações -->\n     <g transform=\"translate(688.872656 377.483125)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\nM 37.78125 79.984375 \nL 47.5 79.984375 \nL 31.59375 61.625 \nL 24.109375 61.625 \nz\n\" id=\"DejaVuSans-250\"/>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-73\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\nM 36.109375 0 \nQ 38.78125 -3.03125 40.09375 -5.59375 \nQ 41.421875 -8.15625 41.421875 -10.5 \nQ 41.421875 -14.84375 38.484375 -17.0625 \nQ 35.5625 -19.28125 29.796875 -19.28125 \nQ 27.5625 -19.28125 25.4375 -18.984375 \nQ 23.3125 -18.703125 21.203125 -18.109375 \nL 21.203125 -11.71875 \nQ 22.875 -12.546875 24.671875 -12.90625 \nQ 26.484375 -13.28125 28.78125 -13.28125 \nQ 31.65625 -13.28125 33.125 -12.109375 \nQ 34.59375 -10.9375 34.59375 -8.6875 \nQ 34.59375 -7.234375 33.53125 -5.109375 \nQ 32.484375 -2.984375 30.296875 0 \nz\n\" id=\"DejaVuSans-231\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\nM 30.4375 66.890625 \nL 27.640625 69.578125 \nQ 26.578125 70.5625 25.765625 71.015625 \nQ 24.96875 71.484375 24.328125 71.484375 \nQ 22.46875 71.484375 21.59375 69.703125 \nQ 20.71875 67.921875 20.609375 63.921875 \nL 14.515625 63.921875 \nQ 14.609375 70.515625 17.09375 74.09375 \nQ 19.59375 77.6875 24.03125 77.6875 \nQ 25.890625 77.6875 27.453125 77 \nQ 29.015625 76.3125 30.828125 74.703125 \nL 33.609375 72.015625 \nQ 34.671875 71.046875 35.484375 70.578125 \nQ 36.296875 70.125 36.921875 70.125 \nQ 38.78125 70.125 39.65625 71.90625 \nQ 40.53125 73.6875 40.640625 77.6875 \nL 46.734375 77.6875 \nQ 46.640625 71.09375 44.140625 67.5 \nQ 41.65625 63.921875 37.21875 63.921875 \nQ 35.359375 63.921875 33.796875 64.59375 \nQ 32.234375 65.28125 30.4375 66.890625 \nz\n\" id=\"DejaVuSans-245\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-250\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"297.119141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"335.982422\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"397.164062\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"428.951172\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"492.427734\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"553.951172\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"585.738281\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"615.230469\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"654.439453\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"715.962891\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"757.076172\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"818.355469\" xlink:href=\"#DejaVuSans-231\"/>\n      <use x=\"873.335938\" xlink:href=\"#DejaVuSans-245\"/>\n      <use x=\"934.517578\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"996.041016\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mcb8846c5c7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"328.718661\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 332.51788)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"284.682414\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 288.481633)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"240.646166\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 244.445385)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"196.609919\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 200.409138)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"152.573672\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.2 -->\n      <g transform=\"translate(20.878125 156.372891)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"108.537424\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.4 -->\n      <g transform=\"translate(20.878125 112.336643)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"43.78125\" xlink:href=\"#mcb8846c5c7\" y=\"64.501177\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.6 -->\n      <g transform=\"translate(20.878125 68.300396)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_15\">\n     <!-- Loss -->\n     <g transform=\"translate(14.798437 196.845312)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pbbe03f6ed5)\" d=\"M 107.190341 37.62358 \nL 113.563114 111.357241 \nL 119.935887 136.355475 \nL 126.30866 178.285727 \nL 132.681433 185.74187 \nL 139.054206 220.160451 \nL 145.426979 202.286984 \nL 151.799752 187.408911 \nL 158.172525 221.413239 \nL 164.545298 207.895345 \nL 170.91807 238.636408 \nL 177.290843 244.273497 \nL 183.663616 229.346695 \nL 190.036389 239.161242 \nL 196.409162 238.256762 \nL 202.781935 271.955239 \nL 215.527481 219.264829 \nL 221.900254 251.04602 \nL 228.273027 227.879964 \nL 234.6458 267.520567 \nL 241.018573 267.225911 \nL 247.391346 248.564948 \nL 253.764119 253.43306 \nL 260.136892 254.414578 \nL 266.509665 290.664235 \nL 272.882438 263.243368 \nL 279.255211 232.660579 \nL 285.627984 262.605459 \nL 292.000757 236.237202 \nL 298.37353 281.162179 \nL 304.746303 278.590762 \nL 311.119075 257.377373 \nL 317.491848 260.071589 \nL 323.864621 263.494322 \nL 330.237394 301.207521 \nL 336.610167 273.79096 \nL 342.98294 241.249204 \nL 349.355713 268.904409 \nL 355.728486 241.131968 \nL 362.101259 289.513997 \nL 368.474032 285.851768 \nL 374.846805 262.520298 \nL 381.219578 263.928327 \nL 387.592351 269.672389 \nL 393.965124 308.13864 \nL 400.337897 281.206196 \nL 406.71067 247.549912 \nL 413.083443 272.8835 \nL 419.456216 244.461089 \nL 425.828989 295.28159 \nL 432.201762 291.043001 \nL 438.574535 265.909959 \nL 444.947308 266.42999 \nL 451.320081 274.276305 \nL 457.692853 313.089576 \nL 464.065626 286.873707 \nL 470.438399 252.466661 \nL 476.811172 275.629266 \nL 483.183945 246.927213 \nL 489.556718 299.559235 \nL 495.929491 294.99864 \nL 502.302264 268.309138 \nL 508.675037 268.16828 \nL 515.04781 277.893966 \nL 521.420583 316.823179 \nL 527.793356 291.427949 \nL 534.166129 256.449059 \nL 540.538902 277.645952 \nL 546.911675 248.860247 \nL 553.284448 302.888053 \nL 559.657221 298.141757 \nL 566.029994 270.088558 \nL 572.402767 269.440373 \nL 578.77554 280.838217 \nL 585.148313 319.751912 \nL 591.521086 295.209304 \nL 597.893858 259.761605 \nL 604.266631 279.200731 \nL 610.639404 250.438243 \nL 617.012177 305.57055 \nL 623.38495 300.715404 \nL 629.757723 271.453554 \nL 636.130496 270.413281 \nL 642.503269 283.295601 \nL 648.876042 322.120185 \nL 655.248815 298.42153 \nL 661.621588 262.574736 \nL 667.994361 280.448164 \nL 674.367134 251.766256 \nL 680.739907 307.790419 \nL 687.11268 302.871609 \nL 693.485453 272.528658 \nL 699.858226 271.187902 \nL 706.230999 285.386502 \nL 712.603772 324.082393 \nL 718.976545 301.196327 \nL 725.349318 265.004441 \nL 731.722091 281.483004 \nL 738.094864 252.910207 \nL 744.467636 309.66622 \nL 750.840409 304.711136 \nL 757.213182 273.394345 \nL 763.585955 271.827649 \nL 769.958728 287.192563 \nL 776.331501 325.740733 \nL 782.704274 303.624326 \nL 789.077047 267.133165 \nL 795.44982 282.365686 \nL 801.822593 253.913825 \nL 808.195366 311.278272 \nL 814.568139 306.303988 \nL 820.940912 274.105 \nL 827.313685 272.374033 \nL 833.686458 288.771897 \nL 840.059231 327.1656 \nL 846.432004 305.77057 \nL 852.804777 269.020568 \nL 859.17755 283.136645 \nL 865.550323 254.80698 \nL 871.923096 312.682843 \nL 878.295869 307.700579 \nL 884.668642 274.698669 \nL 891.041414 272.85468 \nL 897.414187 290.166986 \nL 903.78696 328.406903 \nL 910.159733 307.683669 \nL 916.532506 270.711559 \nL 922.905279 283.822982 \nL 929.278052 255.611025 \nL 935.650825 313.920872 \nL 942.023598 308.938189 \nL 948.396371 275.20265 \nL 954.769144 273.288212 \nL 961.141917 291.40997 \nL 967.51469 329.501168 \nL 973.887463 309.400935 \nL 980.260236 272.239986 \nL 986.633009 284.443844 \nL 993.005782 256.34147 \nL 999.378555 315.022761 \nL 1005.751328 310.045085 \nL 1012.124101 275.637075 \nL 1018.496874 273.68761 \nL 1024.869647 292.525652 \nL 1031.242419 330.475428 \nL 1037.615192 310.951758 \nL 1043.987965 273.632214 \nL 1050.360738 285.012709 \nL 1056.733511 257.009946 \nL 1063.106284 316.011799 \nL 1069.479057 311.043185 \nL 1075.85183 276.016879 \nL 1082.224603 274.061665 \nL 1088.597376 293.53347 \nL 1094.970149 331.350479 \nL 1101.342922 312.359681 \nL 1107.715695 274.908795 \nL 1114.088468 285.539355 \nL 1120.461241 257.625453 \nL 1126.834014 316.905873 \nL 1133.206787 311.949588 \nL 1139.57956 276.353387 \nL 1145.952333 274.416664 \nL 1152.325106 294.449054 \nL 1158.697879 332.142298 \nL 1165.070652 313.643894 \nL 1171.443425 276.086133 \nL 1177.816197 286.031026 \nL 1184.18897 258.195066 \nL 1190.561743 317.719215 \nL 1196.934516 312.778135 \nL 1203.307289 276.655274 \nL 1209.680062 274.75711 \nL 1216.052835 295.285159 \nL 1222.425608 332.863557 \nL 1228.798381 314.820353 \nL 1235.171154 277.177615 \nL 1241.543927 286.493076 \nL 1247.9167 258.724468 \nL 1254.289473 318.463198 \nL 1260.662246 313.539874 \nL 1267.035019 276.929391 \nL 1273.407792 275.085809 \nL 1279.780565 296.052168 \nL 1286.153338 333.524283 \nL 1292.526111 315.902366 \nL 1298.898884 278.193977 \nL 1305.271657 286.929706 \nL 1311.64443 259.218344 \nL 1318.017202 319.147061 \nL 1324.389975 314.243849 \nL 1330.762748 277.180909 \nL 1337.135521 275.405256 \nL 1343.508294 296.758807 \nL 1349.881067 334.13267 \nL 1356.25384 316.901128 \nL 1362.626613 279.144128 \nL 1368.999386 287.344064 \nL 1375.372159 259.680513 \nL 1375.372159 259.680513 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 348.958125 \nL 43.78125 22.798125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 1438.78125 348.958125 \nL 1438.78125 22.798125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 348.958125 \nL 1438.78125 348.958125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.798125 \nL 1438.78125 22.798125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- Regressão Logística: Loss vs Número de Iterações -->\n    <g transform=\"translate(591.375937 16.798125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\nM 28.8125 66.890625 \nL 26.015625 69.578125 \nQ 24.953125 70.5625 24.140625 71.015625 \nQ 23.34375 71.484375 22.703125 71.484375 \nQ 20.84375 71.484375 19.96875 69.703125 \nQ 19.09375 67.921875 18.984375 63.921875 \nL 12.890625 63.921875 \nQ 12.984375 70.515625 15.46875 74.09375 \nQ 17.96875 77.6875 22.40625 77.6875 \nQ 24.265625 77.6875 25.828125 77 \nQ 27.390625 76.3125 29.203125 74.703125 \nL 31.984375 72.015625 \nQ 33.046875 71.046875 33.859375 70.578125 \nQ 34.671875 70.125 35.296875 70.125 \nQ 37.15625 70.125 38.03125 71.90625 \nQ 38.90625 73.6875 39.015625 77.6875 \nL 45.109375 77.6875 \nQ 45.015625 71.09375 42.515625 67.5 \nQ 40.03125 63.921875 35.59375 63.921875 \nQ 33.734375 63.921875 32.171875 64.59375 \nQ 30.609375 65.28125 28.8125 66.890625 \nz\n\" id=\"DejaVuSans-227\"/>\n      <path d=\"M 20.65625 79.984375 \nL 30.375 79.984375 \nL 14.46875 61.625 \nL 6.984375 61.625 \nz\nM 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 13.921875 56 \nz\n\" id=\"DejaVuSans-237\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 11.71875 12.40625 \nL 22.015625 12.40625 \nL 22.015625 0 \nL 11.71875 0 \nz\nM 11.71875 51.703125 \nL 22.015625 51.703125 \nL 22.015625 39.3125 \nL 11.71875 39.3125 \nz\n\" id=\"DejaVuSans-58\"/>\n      <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-82\"/>\n     <use x=\"64.982422\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"126.505859\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"189.982422\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"228.845703\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"290.369141\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"342.46875\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"394.568359\" xlink:href=\"#DejaVuSans-227\"/>\n     <use x=\"455.847656\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"517.029297\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"548.816406\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"602.779297\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"663.960938\" xlink:href=\"#DejaVuSans-103\"/>\n     <use x=\"727.4375\" xlink:href=\"#DejaVuSans-237\"/>\n     <use x=\"755.220703\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"807.320312\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"846.529297\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"874.3125\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"929.292969\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"990.572266\" xlink:href=\"#DejaVuSans-58\"/>\n     <use x=\"1024.263672\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1056.050781\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"1110.013672\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1171.195312\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1223.294922\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1275.394531\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1307.181641\" xlink:href=\"#DejaVuSans-118\"/>\n     <use x=\"1366.361328\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"1418.460938\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1450.248047\" xlink:href=\"#DejaVuSans-78\"/>\n     <use x=\"1525.052734\" xlink:href=\"#DejaVuSans-250\"/>\n     <use x=\"1588.431641\" xlink:href=\"#DejaVuSans-109\"/>\n     <use x=\"1685.84375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1747.367188\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1786.230469\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"1847.412109\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1879.199219\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"1942.675781\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"2004.199219\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"2035.986328\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"2065.478516\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"2104.6875\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"2166.210938\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"2207.324219\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"2268.603516\" xlink:href=\"#DejaVuSans-231\"/>\n     <use x=\"2323.583984\" xlink:href=\"#DejaVuSans-245\"/>\n     <use x=\"2384.765625\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"2446.289062\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbbe03f6ed5\">\n   <rect height=\"326.16\" width=\"1395\" x=\"43.78125\" y=\"22.798125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.figure(figsize=(25,6))\n",
    "plt.plot(lista_iteracao,lista_loss)\n",
    "plt.xlabel(\"Número de Iterações\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Regressão Logística: Loss vs Número de Iterações\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}